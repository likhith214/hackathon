{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install striprtf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hH61-WLx5BL3",
        "outputId": "03aadcd1-947a-4d64-bf41-7801788ebc4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: striprtf in /usr/local/lib/python3.10/dist-packages (0.0.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from striprtf.striprtf import rtf_to_text\n",
        "\n",
        "with open('/content/algoparams_from_ui1.json.rtf', 'r') as file:\n",
        "    rtf_text = file.read()\n",
        "\n",
        "plain_text = rtf_to_text(rtf_text)\n",
        "\n",
        "print(plain_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5_Rx2r85AOd",
        "outputId": "1a707cba-02d6-4f42-ff17-fc211a6e5fbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"session_name\": \"test\",\n",
            "    \"session_description\": \"test\",\n",
            "    \"design_state_data\": {\n",
            "\n",
            "      \"session_info\" : {\n",
            "        \"project_id\": \"1\",\n",
            "        \"experiment_id\": \"kkkk-11\",\n",
            "        \"dataset\":\"iris_modified.csv\",\n",
            "        \"session_name\": \"test\",\n",
            "        \"session_description\": \"test\"\n",
            "        },\n",
            "\n",
            "      \"target\": {\n",
            "        \"prediction_type\": \"Classification\",\n",
            "        \"target\": \"species\",\n",
            "        \"type\":\"classifiation\",\n",
            "        \"partitioning\": true\n",
            "      },\n",
            "      \"train\": {\n",
            "        \"policy\": \"Split the dataset\",\n",
            "        \"time_variable\": \"sepal_length\",\n",
            "        \"sampling_method\": \"No sampling(whole data)\",\n",
            "        \"split\": \"Randomly\",\n",
            "        \"k_fold\": false,\n",
            "        \"train_ratio\": 0.8,\n",
            "        \"random_seed\": 10\n",
            "      },\n",
            "      \"feature_handling\": {\n",
            "        \"sepal_length\": {\n",
            "          \"feature_name\": \"sepal_length\",\n",
            "          \"is_selected\": true,\n",
            "          \"feature_variable_type\": \"numerical\",\n",
            "          \"feature_details\": {\n",
            "            \"numerical_handling\": \"Keep as regular numerical feature\",\n",
            "            \"rescaling\": \"No rescaling\",\n",
            "            \"make_derived_feats\": false,\n",
            "            \"missing_values\": \"Impute\",\n",
            "            \"impute_with\": \"Average of values\"\n",
            "            \n",
            "          }\n",
            "        },\n",
            "        \"sepal_width\": {\n",
            "          \"feature_name\": \"sepal_width\",\n",
            "          \"is_selected\": true,\n",
            "          \"feature_variable_type\": \"numerical\",\n",
            "          \"feature_details\": {\n",
            "            \"numerical_handling\": \"Keep as regular numerical feature\",\n",
            "            \"rescaling\": \"No rescaling\",\n",
            "            \"make_derived_feats\": false,\n",
            "            \"missing_values\": \"Impute\",\n",
            "            \"impute_with\": \"Average of values\"\n",
            "            \n",
            "          }\n",
            "        },\n",
            "        \"petal_length\": {\n",
            "          \"feature_name\": \"petal_length\",\n",
            "          \"is_selected\": true,\n",
            "          \"feature_variable_type\": \"numerical\",\n",
            "          \"feature_details\": {\n",
            "            \"numerical_handling\": \"Keep as regular numerical feature\",\n",
            "            \"rescaling\": \"No rescaling\",\n",
            "            \"make_derived_feats\": false,\n",
            "            \"missing_values\": \"Impute\",\n",
            "            \"impute_with\": \"Average of values\"\n",
            "            \n",
            "          }\n",
            "        },\n",
            "        \"petal_width\": {\n",
            "          \"feature_name\": \"petal_width\",\n",
            "          \"is_selected\": false,\n",
            "          \"feature_variable_type\": \"numerical\",\n",
            "          \"feature_details\": {\n",
            "            \"numerical_handling\": \"Keep as regular numerical feature\",\n",
            "            \"rescaling\": \"No rescaling\",\n",
            "            \"make_derived_feats\": false,\n",
            "            \"missing_values\": \"Impute\",\n",
            "            \"impute_with\": \"Average of values\"            \n",
            "          }\n",
            "        },\n",
            "        \"species\": {\n",
            "          \"feature_name\": \"species\",\n",
            "          \"is_selected\": true,\n",
            "          \"feature_variable_type\": \"text\",\n",
            "          \"feature_details\": {\n",
            "            \"text_handling\": \"Tokenize and hash\",\n",
            "            \"hash_columns\": 0\n",
            "          }\n",
            "        }\n",
            "      },\n",
            "      \n",
            "      \"algorithms\": {\n",
            "        \"RandomForestClassifier\": {\n",
            "          \"model_name\": \"Random Forest Classifier\",\n",
            "          \"is_selected\": true,\n",
            "          \"min_trees\": 10,\n",
            "          \"max_trees\": 30,\n",
            "          \"feature_sampling_statergy\": \"Default\",\n",
            "          \"min_depth\": 20,\n",
            "          \"max_depth\": 30,\n",
            "          \"min_samples_per_leaf_min_value\": 5,\n",
            "          \"min_samples_per_leaf_max_value\": 50,\n",
            "          \"parallelism\": 0\n",
            "        },\n",
            "        \"RandomForestRegressor\": {\n",
            "          \"model_name\": \"Random Forest Regressor\",\n",
            "          \"is_selected\": false,\n",
            "          \"min_trees\": 10,\n",
            "          \"max_trees\": 20,\n",
            "          \"feature_sampling_statergy\": \"Default\",\n",
            "          \"min_depth\": 20,\n",
            "          \"max_depth\": 25,\n",
            "          \"min_samples_per_leaf_min_value\": 5,\n",
            "          \"min_samples_per_leaf_max_value\": 10,\n",
            "          \"parallelism\": 0\n",
            "        },\n",
            "        \n",
            "        \"LinearRegression\": {\n",
            "          \"model_name\": \"LinearRegression\",\n",
            "          \"is_selected\": false,\n",
            "          \"parallelism\": 2,\n",
            "          \"min_iter\":30,\n",
            "          \"max_iter\":50,\n",
            "          \"min_regparam\":0.5,\n",
            "          \"max_regparam\":0.8,\n",
            "          \"min_elasticnet\":0.5,\n",
            "          \"max_elasticnet\":0.8\n",
            "        },\n",
            "        \"LogisticRegression\": {\n",
            "          \"model_name\": \"LogisticRegression\",\n",
            "          \"is_selected\": false,\n",
            "          \"parallelism\": 2,\n",
            "          \"min_iter\":30,\n",
            "          \"max_iter\":50,\n",
            "          \"min_regparam\":0.5,\n",
            "          \"max_regparam\":0.8,\n",
            "          \"min_elasticnet\":0.5,\n",
            "          \"max_elasticnet\":0.8\n",
            "        },\n",
            "        \"RidgeRegression\": {\n",
            "          \"model_name\": \"RidgeRegression\",\n",
            "          \"is_selected\": false,\n",
            "          \"regularization_term\": \"Specify values to test\",\n",
            "          \"min_iter\":30,\n",
            "          \"max_iter\":50,\n",
            "          \"min_regparam\":0.5,\n",
            "          \"max_regparam\":0.8\n",
            "        },\n",
            "        \"LassoRegression\": {\n",
            "          \"model_name\": \"Lasso Regression\",\n",
            "          \"is_selected\": false,\n",
            "          \"regularization_term\": \"Specify values to test\",\n",
            "          \"min_iter\":30,\n",
            "          \"max_iter\":50,\n",
            "          \"min_regparam\":0.5,\n",
            "          \"max_regparam\":0.8\n",
            "        },\n",
            "        \"ElasticNetRegression\": {\n",
            "          \"model_name\": \"Lasso Regression\",\n",
            "          \"is_selected\": false,\n",
            "          \"regularization_term\": \"Specify values to test\",\n",
            "          \"min_iter\":30,\n",
            "          \"max_iter\":50,\n",
            "          \"min_regparam\":0.5,\n",
            "          \"max_regparam\":0.8,\n",
            "          \"min_elasticnet\":0.5,\n",
            "          \"max_elasticnet\":0.8\n",
            "        },\n",
            "        \"xg_boost\": {\n",
            "          \"model_name\": \"XG Boost\",\n",
            "          \"is_selected\": false,\n",
            "          \"use_gradient_boosted_tree\": true,\n",
            "          \"dart\": true,\n",
            "          \"tree_method\": \"\",\n",
            "          \"random_state\": 0,\n",
            "          \"max_num_of_trees\": 0,\n",
            "          \"early_stopping\": true,\n",
            "          \"early_stopping_rounds\": 2,\n",
            "          \"max_depth_of_tree\": [56, 89], \n",
            "          \"learningRate\": [89, 76],\n",
            "          \"l1_regularization\": [77],\n",
            "          \"l2_regularization\": [78],\n",
            "          \"gamma\": [68],\n",
            "          \"min_child_weight\": [67],\n",
            "          \"sub_sample\": [67],\n",
            "          \"col_sample_by_tree\": [67],\n",
            "          \"replace_missing_values\": false,\n",
            "          \"parallelism\": 0\n",
            "        },\n",
            "        \"DecisionTreeRegressor\": {\n",
            "          \"model_name\": \"Decision Tree\",\n",
            "          \"is_selected\": false,\n",
            "          \"min_depth\":4,\n",
            "          \"max_depth\": 7,\n",
            "          \"use_gini\": false,\n",
            "          \"use_entropy\": true,\n",
            "          \"min_samples_per_leaf\": [12, 6],\n",
            "          \"use_best\": true,\n",
            "          \"use_random\": true\n",
            "        },\n",
            "        \"DecisionTreeClassifier\": {\n",
            "          \"model_name\": \"Decision Tree\",\n",
            "          \"is_selected\": true,\n",
            "          \"min_depth\":4,\n",
            "          \"max_depth\": 7,\n",
            "          \"use_gini\": false,\n",
            "          \"use_entropy\": true,\n",
            "          \"min_samples_per_leaf\": [12, 6],\n",
            "          \"use_best\": true,\n",
            "          \"use_random\": false\n",
            "        },\n",
            "        \"SVM\": {\n",
            "          \"model_name\": \"Support Vector Machine\",\n",
            "          \"is_selected\": false,\n",
            "          \"linear_kernel\": true,\n",
            "          \"rep_kernel\": true,\n",
            "          \"polynomial_kernel\": true,\n",
            "          \"sigmoid_kernel\": true,\n",
            "          \"c_value\": [566, 79],\n",
            "          \"auto\": true,\n",
            "          \"scale\": true,\n",
            "          \"custom_gamma_values\": true,\n",
            "          \"tolerance\": 7,\n",
            "          \"max_iterations\": 7\n",
            "        },\n",
            "        \n",
            "        \"KNN\": {\n",
            "          \"model_name\": \"KNN\",\n",
            "          \"is_selected\": false,\n",
            "          \"k_value\": [78],\n",
            "          \"distance_weighting\": true,\n",
            "          \"neighbour_finding_algorithm\": \"Automatic\",\n",
            "          \"random_state\": 0,\n",
            "          \"p_value\": 0\n",
            "        },\n",
            "          \"neural_network\": {\n",
            "          \"model_name\": \"Neural Network\",\n",
            "          \"is_selected\": false,\n",
            "          \"hidden_layer_sizes\": [67, 89],\n",
            "          \"activation\": \"\",\n",
            "          \"alpha_value\": 0,\n",
            "          \"max_iterations\": 0,\n",
            "          \"convergence_tolerance\": 0,\n",
            "          \"early_stopping\": true,\n",
            "          \"solver\": \"ADAM\",\n",
            "          \"shuffle_data\": true,\n",
            "          \"initial_learning_rate\": 0,\n",
            "          \"automatic_batching\": true,\n",
            "          \"beta_1\": 0,\n",
            "          \"beta_2\": 0,\n",
            "          \"epsilon\": 0,\n",
            "          \"power_t\": 0,\n",
            "          \"momentum\": 0,\n",
            "          \"use_nesterov_momentum\": false\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: export plain text variable as a text file\n",
        "\n",
        "with open('/content/algoparams_from_ui1.txt', 'w') as file:\n",
        "    file.write(plain_text)\n"
      ],
      "metadata": {
        "id": "eEXdMtJFPuJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Read the CSV file\n",
        "file_path = \"/content/iris_modified.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "print(\"CSV file content:\")\n",
        "print(data.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_dIzZrmAQxB",
        "outputId": "b4288f51-99fa-445c-fa47-2ea3e01749ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file content:\n",
            "   sepal_length  sepal_width  petal_length  petal_width      species\n",
            "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
            "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
            "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
            "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
            "4           5.0          3.6           1.4          0.2  Iris-setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import json\n",
        "\n",
        "# Load the JSON data from the text file\n",
        "with open(\"/content/algoparams_from_ui1.txt\", \"r\") as file:\n",
        "    json_data = json.load(file)\n",
        "\n",
        "# Extract values from session_info dictionary\n",
        "session_info = json_data['design_state_data']['session_info']\n",
        "session_name = session_info['session_name']\n",
        "session_description = session_info['session_description']\n",
        "project_id = session_info['project_id']\n",
        "experiment_id = session_info['experiment_id']\n",
        "dataset = session_info['dataset']\n",
        "\n",
        "# Display the extracted values\n",
        "print(\"Session Info:\")\n",
        "print(f\"Session Name: {session_name}\")\n",
        "print(f\"Session Description: {session_description}\")\n",
        "print(f\"Project ID: {project_id}\")\n",
        "print(f\"Experiment ID: {experiment_id}\")\n",
        "print(f\"Dataset: {dataset}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiLLdDo7PgeB",
        "outputId": "37182099-f9e7-40e6-ef63-8e6406411a91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Session Info:\n",
            "Session Name: test\n",
            "Session Description: test\n",
            "Project ID: 1\n",
            "Experiment ID: kkkk-11\n",
            "Dataset: iris_modified.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting information from the 'target' dictionary\n",
        "target_info = json_data['design_state_data']['target']\n",
        "target_variable = target_info['target']\n",
        "prediction_type = target_info['prediction_type']\n",
        "task_type = target_info['type']\n",
        "\n",
        "# Determine if it's a classification or regression task\n",
        "task_type_label = \"Classification\" if task_type.lower() == \"classification\" else \"Regression\"\n",
        "\n",
        "# Display the extracted information\n",
        "print(\"\\nTarget Information:\")\n",
        "print(f\"Target Variable: {target_variable}\")\n",
        "print(f\"Prediction Type: {prediction_type}\")\n",
        "print(f\"Task Type: {task_type_label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJwWPB-KQ6rt",
        "outputId": "b369a925-d497-489f-b393-64ac38b9e27d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Target Information:\n",
            "Target Variable: species\n",
            "Prediction Type: Classification\n",
            "Task Type: Regression\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the feature_handling dictionary\n",
        "feature_handling = json_data['design_state_data']['feature_handling']\n",
        "\n",
        "# Print the extracted feature_handling dictionary\n",
        "print(feature_handling)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4AShUsTFsV4",
        "outputId": "aec8c9f1-05eb-4814-bb58-aee3c5c62267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sepal_length': {'feature_name': 'sepal_length', 'is_selected': True, 'feature_variable_type': 'numerical', 'feature_details': {'numerical_handling': 'Keep as regular numerical feature', 'rescaling': 'No rescaling', 'make_derived_feats': False, 'missing_values': 'Impute', 'impute_with': 'Average of values'}}, 'sepal_width': {'feature_name': 'sepal_width', 'is_selected': True, 'feature_variable_type': 'numerical', 'feature_details': {'numerical_handling': 'Keep as regular numerical feature', 'rescaling': 'No rescaling', 'make_derived_feats': False, 'missing_values': 'Impute', 'impute_with': 'Average of values'}}, 'petal_length': {'feature_name': 'petal_length', 'is_selected': True, 'feature_variable_type': 'numerical', 'feature_details': {'numerical_handling': 'Keep as regular numerical feature', 'rescaling': 'No rescaling', 'make_derived_feats': False, 'missing_values': 'Impute', 'impute_with': 'Average of values'}}, 'petal_width': {'feature_name': 'petal_width', 'is_selected': False, 'feature_variable_type': 'numerical', 'feature_details': {'numerical_handling': 'Keep as regular numerical feature', 'rescaling': 'No rescaling', 'make_derived_feats': False, 'missing_values': 'Impute', 'impute_with': 'Average of values'}}, 'species': {'feature_name': 'species', 'is_selected': True, 'feature_variable_type': 'text', 'feature_details': {'text_handling': 'Tokenize and hash', 'hash_columns': 0}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Iterate over each feature\n",
        "for feature_name, details in feature_handling.items():\n",
        "    if not details.get('is_selected', False):\n",
        "        # Remove the column from the dataframe if not selected\n",
        "        data.drop(columns=[feature_name], inplace=True)\n",
        "        continue\n",
        "\n",
        "    feature_type = details.get('feature_variable_type', None)\n",
        "\n",
        "    if feature_type == 'numerical':\n",
        "        numerical_handling = details['feature_details'].get('numerical_handling', None)\n",
        "        if numerical_handling == 'Keep as regular numerical feature':\n",
        "            # No special handling required for numerical features\n",
        "            pass\n",
        "        elif numerical_handling == 'Rescale':\n",
        "          # Initialize MinMaxScaler\n",
        "            scaler = MinMaxScaler()\n",
        "\n",
        "          # Rescale the column\n",
        "            data[feature_name] = scaler.fit_transform(data[[feature_name]])\n",
        "\n",
        "\n",
        "        elif numerical_handling == 'Impute':\n",
        "            # Impute missing values for numerical features\n",
        "            impute_with = details['feature_details'].get('impute_with', None)\n",
        "            if impute_with == 'Average of values':\n",
        "                data[feature_name].fillna(data[feature_name].mean(), inplace=True)\n",
        "\n",
        "    elif feature_type == 'text':\n",
        "        # Handle text features\n",
        "        text_handling = details['feature_details'].get('text_handling', None)\n",
        "        if text_handling == 'Tokenize and hash':\n",
        "            # Add code for tokenization and hashing if needed\n",
        "            pass\n",
        "\n",
        "# Display the modified data\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fV0iqROoEIZh",
        "outputId": "095cf4d1-88cd-4272-d909-9a281e7e178e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal_length  sepal_width  petal_length      species\n",
            "0           5.1          3.5           1.4  Iris-setosa\n",
            "1           4.9          3.0           1.4  Iris-setosa\n",
            "2           4.7          3.2           1.3  Iris-setosa\n",
            "3           4.6          3.1           1.5  Iris-setosa\n",
            "4           5.0          3.6           1.4  Iris-setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Extract parameters for splitting\n",
        "split_policy = json_data['design_state_data']['train']['policy']\n",
        "time_variable = json_data['design_state_data']['train']['time_variable']\n",
        "sampling_method = json_data['design_state_data']['train']['sampling_method']\n",
        "split_method = json_data['design_state_data']['train']['split']\n",
        "k_fold = json_data['design_state_data']['train']['k_fold']\n",
        "train_ratio = json_data['design_state_data']['train'].get('train_ratio', 0.8)\n",
        "random_seed = json_data['design_state_data']['train'].get('random_seed', None)\n",
        "\n",
        "# Perform dataset splitting based on the specified policy\n",
        "if split_policy == 'Split the dataset':\n",
        "    # Check if the split method is random or time-based\n",
        "    if split_method == 'Randomly':\n",
        "        train_data, test_data = train_test_split(data, train_size=train_ratio, random_state=random_seed)\n",
        "        print(\"Dataset split randomly with train_ratio =\", train_ratio, \"and random_seed =\", random_seed)\n",
        "    elif split_method == 'Time-based':\n",
        "        sorted_data = data.sort_values(by=time_variable)\n",
        "        split_index = int(len(sorted_data) * train_ratio)\n",
        "        train_data = sorted_data[:split_index]\n",
        "        test_data = sorted_data[split_index:]\n",
        "        print(\"Dataset split based on time variable =\", time_variable, \"with train_ratio =\", train_ratio)\n",
        "    else:\n",
        "        print(\"Invalid split method specified in the JSON file.\")\n",
        "else:\n",
        "    print(\"Invalid splitting policy specified in the JSON file.\")\n",
        "\n",
        "# Print the first few rows of train and test data for verification\n",
        "print(\"\\nTrain Data:\")\n",
        "print(train_data.head())\n",
        "print(\"\\nTest Data:\")\n",
        "print(test_data.head())\n",
        "\n",
        "\n",
        "# Assuming 'target' is the target column name (adjust as needed)\n",
        "X_train = train_data.drop(target_variable, axis=1)\n",
        "y_train = train_data[target_variable]\n",
        "\n",
        "X_test = test_data.drop(target_variable, axis=1)\n",
        "y_test = test_data[target_variable]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTl3UzxqYjRi",
        "outputId": "e135424e-1c32-4bd9-9734-554d82aa2dc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset split randomly with train_ratio = 0.8 and random_seed = 10\n",
            "\n",
            "Train Data:\n",
            "     sepal_length  sepal_width  petal_length          species\n",
            "58            6.6          2.9           4.6  Iris-versicolor\n",
            "97            6.2          2.9           4.3  Iris-versicolor\n",
            "129           7.2          3.0           5.8   Iris-virginica\n",
            "114           5.8          2.8           5.1   Iris-virginica\n",
            "146           6.3          2.5           5.0   Iris-virginica\n",
            "\n",
            "Test Data:\n",
            "     sepal_length  sepal_width  petal_length          species\n",
            "87            6.3          2.3           4.4  Iris-versicolor\n",
            "111           6.4          2.7           5.3   Iris-virginica\n",
            "10            5.4          3.7           1.5      Iris-setosa\n",
            "91            6.1          3.0           4.6  Iris-versicolor\n",
            "49            5.0          3.3           1.4      Iris-setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the feature_handling dictionary\n",
        "algorithms = json_data['design_state_data']['algorithms']\n",
        "\n",
        "# Print the extracted feature_handling dictionary\n",
        "print(algorithms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29xRd32wavIL",
        "outputId": "d3abb62a-32b7-4324-cfa3-bebe31173080"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'RandomForestClassifier': {'model_name': 'Random Forest Classifier', 'is_selected': True, 'min_trees': 10, 'max_trees': 30, 'feature_sampling_statergy': 'Default', 'min_depth': 20, 'max_depth': 30, 'min_samples_per_leaf_min_value': 5, 'min_samples_per_leaf_max_value': 50, 'parallelism': 0}, 'RandomForestRegressor': {'model_name': 'Random Forest Regressor', 'is_selected': False, 'min_trees': 10, 'max_trees': 20, 'feature_sampling_statergy': 'Default', 'min_depth': 20, 'max_depth': 25, 'min_samples_per_leaf_min_value': 5, 'min_samples_per_leaf_max_value': 10, 'parallelism': 0}, 'LinearRegression': {'model_name': 'LinearRegression', 'is_selected': False, 'parallelism': 2, 'min_iter': 30, 'max_iter': 50, 'min_regparam': 0.5, 'max_regparam': 0.8, 'min_elasticnet': 0.5, 'max_elasticnet': 0.8}, 'LogisticRegression': {'model_name': 'LogisticRegression', 'is_selected': False, 'parallelism': 2, 'min_iter': 30, 'max_iter': 50, 'min_regparam': 0.5, 'max_regparam': 0.8, 'min_elasticnet': 0.5, 'max_elasticnet': 0.8}, 'RidgeRegression': {'model_name': 'RidgeRegression', 'is_selected': False, 'regularization_term': 'Specify values to test', 'min_iter': 30, 'max_iter': 50, 'min_regparam': 0.5, 'max_regparam': 0.8}, 'LassoRegression': {'model_name': 'Lasso Regression', 'is_selected': False, 'regularization_term': 'Specify values to test', 'min_iter': 30, 'max_iter': 50, 'min_regparam': 0.5, 'max_regparam': 0.8}, 'ElasticNetRegression': {'model_name': 'Lasso Regression', 'is_selected': False, 'regularization_term': 'Specify values to test', 'min_iter': 30, 'max_iter': 50, 'min_regparam': 0.5, 'max_regparam': 0.8, 'min_elasticnet': 0.5, 'max_elasticnet': 0.8}, 'xg_boost': {'model_name': 'XG Boost', 'is_selected': False, 'use_gradient_boosted_tree': True, 'dart': True, 'tree_method': '', 'random_state': 0, 'max_num_of_trees': 0, 'early_stopping': True, 'early_stopping_rounds': 2, 'max_depth_of_tree': [56, 89], 'learningRate': [89, 76], 'l1_regularization': [77], 'l2_regularization': [78], 'gamma': [68], 'min_child_weight': [67], 'sub_sample': [67], 'col_sample_by_tree': [67], 'replace_missing_values': False, 'parallelism': 0}, 'DecisionTreeRegressor': {'model_name': 'Decision Tree', 'is_selected': False, 'min_depth': 4, 'max_depth': 7, 'use_gini': False, 'use_entropy': True, 'min_samples_per_leaf': [12, 6], 'use_best': True, 'use_random': True}, 'DecisionTreeClassifier': {'model_name': 'Decision Tree', 'is_selected': True, 'min_depth': 4, 'max_depth': 7, 'use_gini': False, 'use_entropy': True, 'min_samples_per_leaf': [12, 6], 'use_best': True, 'use_random': False}, 'SVM': {'model_name': 'Support Vector Machine', 'is_selected': False, 'linear_kernel': True, 'rep_kernel': True, 'polynomial_kernel': True, 'sigmoid_kernel': True, 'c_value': [566, 79], 'auto': True, 'scale': True, 'custom_gamma_values': True, 'tolerance': 7, 'max_iterations': 7}, 'KNN': {'model_name': 'KNN', 'is_selected': False, 'k_value': [78], 'distance_weighting': True, 'neighbour_finding_algorithm': 'Automatic', 'random_state': 0, 'p_value': 0}, 'neural_network': {'model_name': 'Neural Network', 'is_selected': False, 'hidden_layer_sizes': [67, 89], 'activation': '', 'alpha_value': 0, 'max_iterations': 0, 'convergence_tolerance': 0, 'early_stopping': True, 'solver': 'ADAM', 'shuffle_data': True, 'initial_learning_rate': 0, 'automatic_batching': True, 'beta_1': 0, 'beta_2': 0, 'epsilon': 0, 'power_t': 0, 'momentum': 0, 'use_nesterov_momentum': False}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdh = json_data['design_state_data']['algorithms']['RandomForestClassifier']\n",
        "\n",
        "# Print the extracted feature_handling dictionary\n",
        "print(rdh)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trSRKj-K0DeB",
        "outputId": "c212df33-8bf8-422b-e320-44e211d29b44"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'model_name': 'Random Forest Classifier', 'is_selected': True, 'min_trees': 10, 'max_trees': 30, 'feature_sampling_statergy': 'Default', 'min_depth': 20, 'max_depth': 30, 'min_samples_per_leaf_min_value': 5, 'min_samples_per_leaf_max_value': 50, 'parallelism': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def compute_classification_metrics(predictor, X_test, y_test):\n",
        "    # Make predictions\n",
        "      predicted_labels = predictor.predict(X_test)\n",
        "\n",
        "    # Compute confusion matrix\n",
        "      cm = confusion_matrix(y_test, predicted_labels)\n",
        "\n",
        "    # Compute classification report\n",
        "      cr = classification_report(y_test, predicted_labels)\n",
        "\n",
        "      print(cm)\n",
        "      print(cr)"
      ],
      "metadata": {
        "id": "p_jGieU6BJh4"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "def compute_regression_metrics(predictor, X_test, y_test):\n",
        "    # Make predictions\n",
        "    predicted_values = predictor.predict(X_test)\n",
        "\n",
        "    # Compute R-squared\n",
        "    r_squared = r2_score(y_test, predicted_values)\n",
        "\n",
        "    # Compute Adjusted R-squared\n",
        "    n = len(y_test)\n",
        "    p = X_test.shape[1]\n",
        "    adj_r_squared = 1 - (1 - r_squared) * ((n - 1) / (n - p - 1))\n",
        "\n",
        "    # Compute RMSE (Root Mean Squared Error)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, predicted_values))\n",
        "    print(predictor)\n",
        "\n",
        "\n",
        "    print(\"R-squared:\", r_squared)\n",
        "    print(\"Adjusted R-squared:\", adj_r_squared)\n",
        "    print(\"RMSE:\", rmse)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Fy-wxXy4BSpT"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "def build_linear_regression_model(params_dict, X_train, X_test, y_train, y_test):\n",
        "    if params_dict.get('is_selected', False):\n",
        "        # Extract hyperparameters\n",
        "        min_iter = params_dict.get('min_iter', 30)\n",
        "        max_iter = params_dict.get('max_iter', 50)\n",
        "        min_regparam = params_dict.get('min_regparam', 0.5)\n",
        "        max_regparam = params_dict.get('max_regparam', 0.8)\n",
        "        min_elasticnet = params_dict.get('min_elasticnet', 0.5)\n",
        "        max_elasticnet = params_dict.get('max_elasticnet', 0.8)\n",
        "\n",
        "        # Initialize model with hyperparameters\n",
        "        model = LinearRegression(n_jobs=params_dict.get('parallelism', 1))\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        if prediction_type==\"Classification\":\n",
        "          compute_classification_metrics(model,X_test, y_test)\n",
        "        else:\n",
        "          compute_regression_metrics(model, X_test, y_test)\n",
        "        return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8q-6rk1LGAiu"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def build_logistic_regression_model(params_dict, X_train, X_test, y_train, y_test):\n",
        "    if params_dict.get('is_selected', False):\n",
        "        # Extract hyperparameters\n",
        "        min_iter = params_dict.get('min_iter', 30)\n",
        "        max_iter = params_dict.get('max_iter', 50)\n",
        "        min_regparam = params_dict.get('min_regparam', 0.5)\n",
        "        max_regparam = params_dict.get('max_regparam', 0.8)\n",
        "        min_elasticnet = params_dict.get('min_elasticnet', 0.5)\n",
        "        max_elasticnet = params_dict.get('max_elasticnet', 0.8)\n",
        "\n",
        "        # Initialize model with hyperparameters\n",
        "        model = LogisticRegression(n_jobs=params_dict.get('parallelism', 1))\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        if prediction_type==\"Classification\":\n",
        "          compute_classification_metrics(model,X_test, y_test)\n",
        "        else:\n",
        "          compute_regression_metrics(model, X_test, y_test)\n",
        "        return model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-mgJ1ALyG-zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "def build_ridge_regression_model(params_dict, X_train, X_test, y_train, y_test):\n",
        "    if params_dict.get('is_selected', False):\n",
        "        # Extract hyperparameters\n",
        "        regularization_term = params_dict.get('regularization_term', 1.0)\n",
        "        min_iter = params_dict.get('min_iter', 30)\n",
        "        max_iter = params_dict.get('max_iter', 50)\n",
        "\n",
        "        # Initialize model with hyperparameters\n",
        "        model = Ridge(alpha=regularization_term,\n",
        "                      max_iter=max_iter,\n",
        "                      min_iter=min_iter)\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        if prediction_type==\"Classification\":\n",
        "          compute_classification_metrics(model,X_test, y_test)\n",
        "        else:\n",
        "          compute_regression_metrics(model, X_test, y_test)\n",
        "        return model\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MqS63j0nH1D2"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "def build_lasso_regression_model(params_dict, X_train, X_test, y_train, y_test, prediction_type):\n",
        "    if params_dict.get('is_selected', False):\n",
        "        # Extract hyperparameters\n",
        "        regularization_term = params_dict.get('regularization_term', 1.0)\n",
        "        min_iter = params_dict.get('min_iter', 30)\n",
        "        max_iter = params_dict.get('max_iter', 50)\n",
        "\n",
        "        # Initialize model with hyperparameters\n",
        "        model = Lasso(alpha=regularization_term,\n",
        "                      max_iter=max_iter,\n",
        "                      min_iter=min_iter)\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        if prediction_type==\"Classification\":\n",
        "          compute_classification_metrics(model,X_test, y_test)\n",
        "        else:\n",
        "          compute_regression_metrics(model, X_test, y_test)\n",
        "        return model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pyugbDU3JEvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "def build_elasticnet_regression_model(params_dict, X_train, X_test, y_train, y_test):\n",
        "    if params_dict.get('is_selected', False):\n",
        "        # Extract hyperparameters\n",
        "        regularization_term = params_dict.get('regularization_term', 1.0)\n",
        "        min_iter = params_dict.get('min_iter', 30)\n",
        "        max_iter = params_dict.get('max_iter', 50)\n",
        "        min_regparam = params_dict.get('min_regparam', 0.5)\n",
        "        max_regparam = params_dict.get('max_regparam', 0.8)\n",
        "        min_elasticnet = params_dict.get('min_elasticnet', 0.5)\n",
        "        max_elasticnet = params_dict.get('max_elasticnet', 0.8)\n",
        "\n",
        "        # Initialize model with hyperparameters\n",
        "        model = ElasticNet(alpha=regularization_term,\n",
        "                           l1_ratio=params_dict.get('min_elasticnet', 0.5),\n",
        "                           max_iter=max_iter,\n",
        "                           min_iter=min_iter)\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        if prediction_type==\"Classification\":\n",
        "          compute_classification_metrics(model,X_test, y_test)\n",
        "        else:\n",
        "          compute_regression_metrics(model, X_test, y_test)\n",
        "        return model\n",
        "\n"
      ],
      "metadata": {
        "id": "QApOGFLwJlJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "def build_xgboost_model(params_dict, X_train, X_test, y_train, y_test):\n",
        "    if params_dict.get('is_selected', False):\n",
        "        # Extract hyperparameters\n",
        "        max_depth_of_tree = params_dict.get('max_depth_of_tree', [3, 6])\n",
        "        learning_rate = params_dict.get('learningRate', [0.1, 0.3])\n",
        "        l1_regularization = params_dict.get('l1_regularization', [0])\n",
        "        l2_regularization = params_dict.get('l2_regularization', [0])\n",
        "        gamma = params_dict.get('gamma', [0])\n",
        "        min_child_weight = params_dict.get('min_child_weight', [1])\n",
        "        sub_sample = params_dict.get('sub_sample', [1])\n",
        "        col_sample_by_tree = params_dict.get('col_sample_by_tree', [1])\n",
        "\n",
        "        # Initialize model with hyperparameters\n",
        "        model = xgb.XGBRegressor(max_depth=max_depth_of_tree,\n",
        "                                  learning_rate=learning_rate,\n",
        "                                  reg_alpha=l1_regularization,\n",
        "                                  reg_lambda=l2_regularization,\n",
        "                                  gamma=gamma,\n",
        "                                  min_child_weight=min_child_weight,\n",
        "                                  subsample=sub_sample,\n",
        "                                  colsample_bytree=col_sample_by_tree,\n",
        "                                  objective='reg:squarederror',\n",
        "                                  random_state=params_dict.get('random_state', 0))\n",
        "\n",
        "        # Train the model\n",
        "        eval_set = [(X_train, y_train), (X_test, y_test)]\n",
        "        model.fit(X_train, y_train, eval_metric=\"rmse\", eval_set=eval_set,\n",
        "                  early_stopping_rounds=params_dict.get('early_stopping_rounds', 2))\n",
        "\n",
        "        if prediction_type==\"Classification\":\n",
        "          compute_classification_metrics(model,X_test, y_test)\n",
        "        else:\n",
        "          compute_regression_metrics(model, X_test, y_test)\n",
        "        return model\n",
        "\n"
      ],
      "metadata": {
        "id": "82Q5tyUXJ-9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "def build_decision_tree_regressor_model(params_dict, X_train, X_test, y_train, y_test):\n",
        "    if params_dict.get('is_selected', False):\n",
        "        # Extract hyperparameters\n",
        "        min_depth = params_dict.get('min_depth', 4)\n",
        "        max_depth = params_dict.get('max_depth', 7)\n",
        "        min_samples_per_leaf = params_dict.get('min_samples_per_leaf', [12, 6])\n",
        "        criterion = 'entropy' if params_dict.get('use_entropy', True) else 'gini'\n",
        "        splitter = 'best' if params_dict.get('use_best', True) else 'random'\n",
        "\n",
        "        # Initialize model with hyperparameters\n",
        "        model = DecisionTreeRegressor(min_samples_leaf=min_samples_per_leaf,\n",
        "                                       max_depth=max_depth,\n",
        "                                       min_samples_split=min_samples_per_leaf,\n",
        "                                       criterion=criterion,\n",
        "                                       splitter=splitter,\n",
        "                                       random_state=params_dict.get('random_state', None))\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        if prediction_type==\"Classification\":\n",
        "          compute_classification_metrics(model,X_test, y_test)\n",
        "        else:\n",
        "          compute_regression_metrics(model, X_test, y_test)\n",
        "        return model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DxP8isjnKl6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "def build_decision_tree_classifier_model(params_dict, X_train, X_test, y_train, y_test):\n",
        "    if params_dict.get('is_selected', False):\n",
        "        # Extract hyperparameters\n",
        "        min_depth = params_dict.get('min_depth', 4)\n",
        "        max_depth = params_dict.get('max_depth', 7)\n",
        "        min_samples_per_leaf = params_dict.get('min_samples_per_leaf', [12, 6])\n",
        "        criterion = 'entropy' if params_dict.get('use_entropy', True) else 'gini'\n",
        "        splitter = 'best' if params_dict.get('use_best', True) else 'random'\n",
        "\n",
        "        # Initialize model with hyperparameters\n",
        "        model = DecisionTreeClassifier(min_samples_leaf=min_samples_per_leaf,\n",
        "                                       max_depth=max_depth,\n",
        "                                       min_samples_split=min_samples_per_leaf,\n",
        "                                       criterion=criterion,\n",
        "                                       splitter=splitter,\n",
        "                                       random_state=params_dict.get('random_state', None))\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        if prediction_type==\"Classification\":\n",
        "          compute_classification_metrics(model,X_test, y_test)\n",
        "        else:\n",
        "          compute_regression_metrics(model, X_test, y_test)\n",
        "        return model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "azU_BuMvLwmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name, model_params in algorithms.items():\n",
        "  print(model_name, model_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmCvoHNiDy55",
        "outputId": "acb93594-f7a0-48fa-e7e8-e2df1d0a6a6f"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier {'model_name': 'Random Forest Classifier', 'is_selected': True, 'min_trees': 10, 'max_trees': 30, 'feature_sampling_statergy': 'Default', 'min_depth': 20, 'max_depth': 30, 'min_samples_per_leaf_min_value': 5, 'min_samples_per_leaf_max_value': 50, 'parallelism': 0}\n",
            "RandomForestRegressor {'model_name': 'Random Forest Regressor', 'is_selected': False, 'min_trees': 10, 'max_trees': 20, 'feature_sampling_statergy': 'Default', 'min_depth': 20, 'max_depth': 25, 'min_samples_per_leaf_min_value': 5, 'min_samples_per_leaf_max_value': 10, 'parallelism': 0}\n",
            "LinearRegression {'model_name': 'LinearRegression', 'is_selected': False, 'parallelism': 2, 'min_iter': 30, 'max_iter': 50, 'min_regparam': 0.5, 'max_regparam': 0.8, 'min_elasticnet': 0.5, 'max_elasticnet': 0.8}\n",
            "LogisticRegression {'model_name': 'LogisticRegression', 'is_selected': False, 'parallelism': 2, 'min_iter': 30, 'max_iter': 50, 'min_regparam': 0.5, 'max_regparam': 0.8, 'min_elasticnet': 0.5, 'max_elasticnet': 0.8}\n",
            "RidgeRegression {'model_name': 'RidgeRegression', 'is_selected': False, 'regularization_term': 'Specify values to test', 'min_iter': 30, 'max_iter': 50, 'min_regparam': 0.5, 'max_regparam': 0.8}\n",
            "LassoRegression {'model_name': 'Lasso Regression', 'is_selected': False, 'regularization_term': 'Specify values to test', 'min_iter': 30, 'max_iter': 50, 'min_regparam': 0.5, 'max_regparam': 0.8}\n",
            "ElasticNetRegression {'model_name': 'Lasso Regression', 'is_selected': False, 'regularization_term': 'Specify values to test', 'min_iter': 30, 'max_iter': 50, 'min_regparam': 0.5, 'max_regparam': 0.8, 'min_elasticnet': 0.5, 'max_elasticnet': 0.8}\n",
            "xg_boost {'model_name': 'XG Boost', 'is_selected': False, 'use_gradient_boosted_tree': True, 'dart': True, 'tree_method': '', 'random_state': 0, 'max_num_of_trees': 0, 'early_stopping': True, 'early_stopping_rounds': 2, 'max_depth_of_tree': [56, 89], 'learningRate': [89, 76], 'l1_regularization': [77], 'l2_regularization': [78], 'gamma': [68], 'min_child_weight': [67], 'sub_sample': [67], 'col_sample_by_tree': [67], 'replace_missing_values': False, 'parallelism': 0}\n",
            "DecisionTreeRegressor {'model_name': 'Decision Tree', 'is_selected': False, 'min_depth': 4, 'max_depth': 7, 'use_gini': False, 'use_entropy': True, 'min_samples_per_leaf': [12, 6], 'use_best': True, 'use_random': True}\n",
            "DecisionTreeClassifier {'model_name': 'Decision Tree', 'is_selected': True, 'min_depth': 4, 'max_depth': 7, 'use_gini': False, 'use_entropy': True, 'min_samples_per_leaf': [12, 6], 'use_best': True, 'use_random': False}\n",
            "SVM {'model_name': 'Support Vector Machine', 'is_selected': False, 'linear_kernel': True, 'rep_kernel': True, 'polynomial_kernel': True, 'sigmoid_kernel': True, 'c_value': [566, 79], 'auto': True, 'scale': True, 'custom_gamma_values': True, 'tolerance': 7, 'max_iterations': 7}\n",
            "KNN {'model_name': 'KNN', 'is_selected': False, 'k_value': [78], 'distance_weighting': True, 'neighbour_finding_algorithm': 'Automatic', 'random_state': 0, 'p_value': 0}\n",
            "neural_network {'model_name': 'Neural Network', 'is_selected': False, 'hidden_layer_sizes': [67, 89], 'activation': '', 'alpha_value': 0, 'max_iterations': 0, 'convergence_tolerance': 0, 'early_stopping': True, 'solver': 'ADAM', 'shuffle_data': True, 'initial_learning_rate': 0, 'automatic_batching': True, 'beta_1': 0, 'beta_2': 0, 'epsilon': 0, 'power_t': 0, 'momentum': 0, 'use_nesterov_momentum': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: now create a function which will take a dictionary algorithms and then it will take out the dictiornay of each model and call out a function with the name of the model\n",
        "\n",
        "def call_model_functions(algorithms):\n",
        "  for model_name, model_params in algorithms.items():\n",
        "    # Check if the model name is valid\n",
        "\n",
        "\n",
        "    if model_name=='RandomForestClassifier':\n",
        "      rdh = json_data['design_state_data']['algorithms']['RandomForestClassifier']\n",
        "      if rdh.get('is_selected', False):\n",
        "        model1 = build_model(rdh, X_train, X_test, y_train, y_test)\n",
        "        print(\"RandomForestClassifier:\", model1)\n",
        "\n",
        "    elif model_name==\"RandomForestRegressor\":\n",
        "      rfr = json_data['design_state_data']['algorithms']['RandomForestRegressor']\n",
        "      if rfr.get('is_selected', False):\n",
        "        model2 = regress(rfr, X_train, y_train)\n",
        "        print(\"RandomForestRegressor:\", model2)\n",
        "\n",
        "    elif model_name==\"LinearRegression\":\n",
        "      lr = json_data['design_state_data']['algorithms']['LinearRegression']\n",
        "      if lr.get('is_selected', False):\n",
        "        model3 = build_linear_regression_model(lr, X_train, X_test, y_train, y_test)\n",
        "        print(\"LinearRegression:\", model3)\n",
        "\n",
        "    elif model_name==\"LogisticRegression\":\n",
        "      lor = json_data['design_state_data']['algorithms']['LogisticRegression']\n",
        "      if lor.get('is_selected', False):\n",
        "        model4 = build_logistic_regression_model(lor, X_train, X_test, y_train, y_test)\n",
        "        print(\"LogisticRegression:\", model4)\n",
        "\n",
        "    elif model_name==\"RidgeRegression\":\n",
        "      rg = json_data['design_state_data']['algorithms']['RidgeRegression']\n",
        "      if rg.get('is_selected', False):\n",
        "        model5 = build_ridge_regression_model(rg, X_train, X_test, y_train, y_test)\n",
        "        print(\"RidgeRegression:\", model5)\n",
        "\n",
        "    elif model_name==\"LassoRegression\":\n",
        "      ls = json_data['design_state_data']['algorithms']['LassoRegression']\n",
        "      if ls.get('is_selected', False):\n",
        "        model6 = build_lasso_regression_model(ls, X_train, X_test, y_train, y_test)\n",
        "        print(\"LassoRegression:\", model6)\n",
        "\n",
        "    elif model_name==\"ElasticNetRegression\":\n",
        "      ela = json_data['design_state_data']['algorithms']['ElasticNetRegression']\n",
        "      if ela.get('is_selected', False):\n",
        "        model7 = build_elasticnet_regression_model(ela, X_train, X_test, y_train, y_test)\n",
        "        print(\"ElasticNetRegression:\", model7)\n",
        "\n",
        "    elif model_name==\"xg_boost\":\n",
        "      xg = json_data['design_state_data']['algorithms']['xg_boost']\n",
        "      if xg.get('is_selected', False):\n",
        "        model8 = build_xgboost_model(xg, X_train, X_test, y_train, y_test)\n",
        "        print(\"xg_boost:\", model8)\n",
        "\n",
        "    elif model_name==\"DecisionTreeRegressor\":\n",
        "      dr = json_data['design_state_data']['algorithms']['DecisionTreeRegressor']\n",
        "      if dr.get('is_selected', False):\n",
        "        model9 = build_decision_tree_regressor_model(dr, X_train, X_test, y_train, y_test)\n",
        "        print(\"DecisionTreeRegressor:\", model9)\n",
        "\n",
        "    elif model_name==\"DecisionTreeClassifier\":\n",
        "      dc = json_data['design_state_data']['algorithms']['DecisionTreeClassifier']\n",
        "      if dc.get('is_selected', False):\n",
        "        model10 = build_decision_tree_classifier_model(dc, X_train, X_test, y_train, y_test)\n",
        "        print(\"DecisionTreeClassifier:\", model10)\n",
        "\n",
        "    else :\n",
        "      print(\"sorry not enough time \")\n",
        "\n",
        "call_model_functions(algorithms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2p6h5zvI8lqi",
        "outputId": "b8b03c99-3b15-4819-fa35-4df87d1ef5e1"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[10  0  0]\n",
            " [ 0 11  2]\n",
            " [ 0  0  7]]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "    Iris-setosa       1.00      1.00      1.00        10\n",
            "Iris-versicolor       1.00      0.85      0.92        13\n",
            " Iris-virginica       0.78      1.00      0.88         7\n",
            "\n",
            "       accuracy                           0.93        30\n",
            "      macro avg       0.93      0.95      0.93        30\n",
            "   weighted avg       0.95      0.93      0.93        30\n",
            "\n",
            "Model: RandomForestClassifier(max_depth=30, min_samples_leaf=5, n_estimators=10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S4vFkb9bGBhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "def build_model(params_dict, X_train, X_test, y_train, y_test):\n",
        "    # Extract hyperparameters\n",
        "    min_trees = params_dict.get('min_trees', 10)\n",
        "    max_trees = params_dict.get('max_trees', 30)\n",
        "    min_depth = params_dict.get('min_depth', None)\n",
        "    max_depth = params_dict.get('max_depth', None)\n",
        "    min_samples_per_leaf_min_value = params_dict.get('min_samples_per_leaf_min_value', 5)\n",
        "    parallelism = params_dict.get('parallelism', 0)\n",
        "\n",
        "    # Initialize model with hyperparameters\n",
        "    model = RandomForestClassifier(n_estimators=min_trees,\n",
        "\n",
        "                                   max_depth=max_depth,\n",
        "                                   min_samples_leaf=min_samples_per_leaf_min_value,\n",
        "                                   )\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "    if prediction_type==\"Classification\":\n",
        "      compute_classification_metrics(model,X_test, y_test)\n",
        "    else:\n",
        "      compute_regression_metrics(model, X_test, y_test)\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "39drlz9039NA"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "\n",
        "def regress(params_dict, X_train, y_train):\n",
        "    # Extract hyperparameters\n",
        "    min_trees = params_dict.get('min_trees', 10)\n",
        "    max_trees = params_dict.get('max_trees', 20)\n",
        "    min_depth = params_dict.get('min_depth', None)\n",
        "    max_depth = params_dict.get('max_depth', None)\n",
        "    min_samples_per_leaf_min_value = params_dict.get('min_samples_per_leaf_min_value', 5)\n",
        "    min_samples_per_leaf_max_value = params_dict.get('min_samples_per_leaf_max_value', 10)\n",
        "    parallelism = params_dict.get('parallelism', 0)\n",
        "\n",
        "    # Initialize model with hyperparameters\n",
        "    model = RandomForestRegressor(n_estimators=min_trees,\n",
        "                                   max_depth=max_depth,\n",
        "                                   min_samples_leaf=min_samples_per_leaf_min_value,\n",
        "                                   )\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "    if prediction_type==\"Classification\":\n",
        "      compute_classification_metrics(model,X_test, y_test)\n",
        "    else:\n",
        "      compute_regression_metrics(model, X_test, y_test)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "pJIX-Txi7J8I"
      },
      "execution_count": 142,
      "outputs": []
    }
  ]
}
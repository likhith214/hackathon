{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install striprtf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hH61-WLx5BL3",
        "outputId": "a65801c7-4ba6-4b6a-e59f-0e6812e73a06"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: striprtf in /usr/local/lib/python3.10/dist-packages (0.0.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from striprtf.striprtf import rtf_to_text\n",
        "\n",
        "with open('/content/algoparams_from_ui1.json.rtf', 'r') as file:\n",
        "    rtf_text = file.read()\n",
        "\n",
        "plain_text = rtf_to_text(rtf_text)\n",
        "\n",
        "print(plain_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5_Rx2r85AOd",
        "outputId": "767bb76a-1a9c-4631-c4b9-94698c898fb7"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"session_name\": \"test\",\n",
            "    \"session_description\": \"test\",\n",
            "    \"design_state_data\": {\n",
            "\n",
            "      \"session_info\" : {\n",
            "        \"project_id\": \"1\",\n",
            "        \"experiment_id\": \"kkkk-11\",\n",
            "        \"dataset\":\"iris_modified.csv\",\n",
            "        \"session_name\": \"test\",\n",
            "        \"session_description\": \"test\"\n",
            "        },\n",
            "\n",
            "      \"target\": {\n",
            "        \"prediction_type\": \"Classification\",\n",
            "        \"target\": \"species\",\n",
            "        \"type\":\"classifiation\",\n",
            "        \"partitioning\": true\n",
            "      },\n",
            "      \"train\": {\n",
            "        \"policy\": \"Split the dataset\",\n",
            "        \"time_variable\": \"sepal_length\",\n",
            "        \"sampling_method\": \"No sampling(whole data)\",\n",
            "        \"split\": \"Randomly\",\n",
            "        \"k_fold\": false,\n",
            "        \"train_ratio\": 0.8,\n",
            "        \"random_seed\": 10\n",
            "      },\n",
            "      \"feature_handling\": {\n",
            "        \"sepal_length\": {\n",
            "          \"feature_name\": \"sepal_length\",\n",
            "          \"is_selected\": true,\n",
            "          \"feature_variable_type\": \"numerical\",\n",
            "          \"feature_details\": {\n",
            "            \"numerical_handling\": \"Keep as regular numerical feature\",\n",
            "            \"rescaling\": \"No rescaling\",\n",
            "            \"make_derived_feats\": false,\n",
            "            \"missing_values\": \"Impute\",\n",
            "            \"impute_with\": \"Average of values\"\n",
            "            \n",
            "          }\n",
            "        },\n",
            "        \"sepal_width\": {\n",
            "          \"feature_name\": \"sepal_width\",\n",
            "          \"is_selected\": true,\n",
            "          \"feature_variable_type\": \"numerical\",\n",
            "          \"feature_details\": {\n",
            "            \"numerical_handling\": \"Keep as regular numerical feature\",\n",
            "            \"rescaling\": \"No rescaling\",\n",
            "            \"make_derived_feats\": false,\n",
            "            \"missing_values\": \"Impute\",\n",
            "            \"impute_with\": \"Average of values\"\n",
            "            \n",
            "          }\n",
            "        },\n",
            "        \"petal_length\": {\n",
            "          \"feature_name\": \"petal_length\",\n",
            "          \"is_selected\": true,\n",
            "          \"feature_variable_type\": \"numerical\",\n",
            "          \"feature_details\": {\n",
            "            \"numerical_handling\": \"Keep as regular numerical feature\",\n",
            "            \"rescaling\": \"No rescaling\",\n",
            "            \"make_derived_feats\": false,\n",
            "            \"missing_values\": \"Impute\",\n",
            "            \"impute_with\": \"Average of values\"\n",
            "            \n",
            "          }\n",
            "        },\n",
            "        \"petal_width\": {\n",
            "          \"feature_name\": \"petal_width\",\n",
            "          \"is_selected\": false,\n",
            "          \"feature_variable_type\": \"numerical\",\n",
            "          \"feature_details\": {\n",
            "            \"numerical_handling\": \"Keep as regular numerical feature\",\n",
            "            \"rescaling\": \"No rescaling\",\n",
            "            \"make_derived_feats\": false,\n",
            "            \"missing_values\": \"Impute\",\n",
            "            \"impute_with\": \"Average of values\"            \n",
            "          }\n",
            "        },\n",
            "        \"species\": {\n",
            "          \"feature_name\": \"species\",\n",
            "          \"is_selected\": true,\n",
            "          \"feature_variable_type\": \"text\",\n",
            "          \"feature_details\": {\n",
            "            \"text_handling\": \"Tokenize and hash\",\n",
            "            \"hash_columns\": 0\n",
            "          }\n",
            "        }\n",
            "      },\n",
            "      \n",
            "      \"algorithms\": {\n",
            "        \"RandomForestClassifier\": {\n",
            "          \"model_name\": \"Random Forest Classifier\",\n",
            "          \"is_selected\": true,\n",
            "          \"min_trees\": 10,\n",
            "          \"max_trees\": 30,\n",
            "          \"feature_sampling_statergy\": \"Default\",\n",
            "          \"min_depth\": 20,\n",
            "          \"max_depth\": 30,\n",
            "          \"min_samples_per_leaf_min_value\": 5,\n",
            "          \"min_samples_per_leaf_max_value\": 50,\n",
            "          \"parallelism\": 0\n",
            "        },\n",
            "        \"RandomForestRegressor\": {\n",
            "          \"model_name\": \"Random Forest Regressor\",\n",
            "          \"is_selected\": false,\n",
            "          \"min_trees\": 10,\n",
            "          \"max_trees\": 20,\n",
            "          \"feature_sampling_statergy\": \"Default\",\n",
            "          \"min_depth\": 20,\n",
            "          \"max_depth\": 25,\n",
            "          \"min_samples_per_leaf_min_value\": 5,\n",
            "          \"min_samples_per_leaf_max_value\": 10,\n",
            "          \"parallelism\": 0\n",
            "        },\n",
            "        \n",
            "        \"LinearRegression\": {\n",
            "          \"model_name\": \"LinearRegression\",\n",
            "          \"is_selected\": false,\n",
            "          \"parallelism\": 2,\n",
            "          \"min_iter\":30,\n",
            "          \"max_iter\":50,\n",
            "          \"min_regparam\":0.5,\n",
            "          \"max_regparam\":0.8,\n",
            "          \"min_elasticnet\":0.5,\n",
            "          \"max_elasticnet\":0.8\n",
            "        },\n",
            "        \"LogisticRegression\": {\n",
            "          \"model_name\": \"LogisticRegression\",\n",
            "          \"is_selected\": false,\n",
            "          \"parallelism\": 2,\n",
            "          \"min_iter\":30,\n",
            "          \"max_iter\":50,\n",
            "          \"min_regparam\":0.5,\n",
            "          \"max_regparam\":0.8,\n",
            "          \"min_elasticnet\":0.5,\n",
            "          \"max_elasticnet\":0.8\n",
            "        },\n",
            "        \"RidgeRegression\": {\n",
            "          \"model_name\": \"RidgeRegression\",\n",
            "          \"is_selected\": false,\n",
            "          \"regularization_term\": \"Specify values to test\",\n",
            "          \"min_iter\":30,\n",
            "          \"max_iter\":50,\n",
            "          \"min_regparam\":0.5,\n",
            "          \"max_regparam\":0.8\n",
            "        },\n",
            "        \"LassoRegression\": {\n",
            "          \"model_name\": \"Lasso Regression\",\n",
            "          \"is_selected\": false,\n",
            "          \"regularization_term\": \"Specify values to test\",\n",
            "          \"min_iter\":30,\n",
            "          \"max_iter\":50,\n",
            "          \"min_regparam\":0.5,\n",
            "          \"max_regparam\":0.8\n",
            "        },\n",
            "        \"ElasticNetRegression\": {\n",
            "          \"model_name\": \"Lasso Regression\",\n",
            "          \"is_selected\": false,\n",
            "          \"regularization_term\": \"Specify values to test\",\n",
            "          \"min_iter\":30,\n",
            "          \"max_iter\":50,\n",
            "          \"min_regparam\":0.5,\n",
            "          \"max_regparam\":0.8,\n",
            "          \"min_elasticnet\":0.5,\n",
            "          \"max_elasticnet\":0.8\n",
            "        },\n",
            "        \"xg_boost\": {\n",
            "          \"model_name\": \"XG Boost\",\n",
            "          \"is_selected\": false,\n",
            "          \"use_gradient_boosted_tree\": true,\n",
            "          \"dart\": true,\n",
            "          \"tree_method\": \"\",\n",
            "          \"random_state\": 0,\n",
            "          \"max_num_of_trees\": 0,\n",
            "          \"early_stopping\": true,\n",
            "          \"early_stopping_rounds\": 2,\n",
            "          \"max_depth_of_tree\": [56, 89], \n",
            "          \"learningRate\": [89, 76],\n",
            "          \"l1_regularization\": [77],\n",
            "          \"l2_regularization\": [78],\n",
            "          \"gamma\": [68],\n",
            "          \"min_child_weight\": [67],\n",
            "          \"sub_sample\": [67],\n",
            "          \"col_sample_by_tree\": [67],\n",
            "          \"replace_missing_values\": false,\n",
            "          \"parallelism\": 0\n",
            "        },\n",
            "        \"DecisionTreeRegressor\": {\n",
            "          \"model_name\": \"Decision Tree\",\n",
            "          \"is_selected\": false,\n",
            "          \"min_depth\":4,\n",
            "          \"max_depth\": 7,\n",
            "          \"use_gini\": false,\n",
            "          \"use_entropy\": true,\n",
            "          \"min_samples_per_leaf\": [12, 6],\n",
            "          \"use_best\": true,\n",
            "          \"use_random\": true\n",
            "        },\n",
            "        \"DecisionTreeClassifier\": {\n",
            "          \"model_name\": \"Decision Tree\",\n",
            "          \"is_selected\": true,\n",
            "          \"min_depth\":4,\n",
            "          \"max_depth\": 7,\n",
            "          \"use_gini\": false,\n",
            "          \"use_entropy\": true,\n",
            "          \"min_samples_per_leaf\": [12, 6],\n",
            "          \"use_best\": true,\n",
            "          \"use_random\": false\n",
            "        },\n",
            "        \"SVM\": {\n",
            "          \"model_name\": \"Support Vector Machine\",\n",
            "          \"is_selected\": false,\n",
            "          \"linear_kernel\": true,\n",
            "          \"rep_kernel\": true,\n",
            "          \"polynomial_kernel\": true,\n",
            "          \"sigmoid_kernel\": true,\n",
            "          \"c_value\": [566, 79],\n",
            "          \"auto\": true,\n",
            "          \"scale\": true,\n",
            "          \"custom_gamma_values\": true,\n",
            "          \"tolerance\": 7,\n",
            "          \"max_iterations\": 7\n",
            "        },\n",
            "        \n",
            "        \"KNN\": {\n",
            "          \"model_name\": \"KNN\",\n",
            "          \"is_selected\": false,\n",
            "          \"k_value\": [78],\n",
            "          \"distance_weighting\": true,\n",
            "          \"neighbour_finding_algorithm\": \"Automatic\",\n",
            "          \"random_state\": 0,\n",
            "          \"p_value\": 0\n",
            "        },\n",
            "          \"neural_network\": {\n",
            "          \"model_name\": \"Neural Network\",\n",
            "          \"is_selected\": false,\n",
            "          \"hidden_layer_sizes\": [67, 89],\n",
            "          \"activation\": \"\",\n",
            "          \"alpha_value\": 0,\n",
            "          \"max_iterations\": 0,\n",
            "          \"convergence_tolerance\": 0,\n",
            "          \"early_stopping\": true,\n",
            "          \"solver\": \"ADAM\",\n",
            "          \"shuffle_data\": true,\n",
            "          \"initial_learning_rate\": 0,\n",
            "          \"automatic_batching\": true,\n",
            "          \"beta_1\": 0,\n",
            "          \"beta_2\": 0,\n",
            "          \"epsilon\": 0,\n",
            "          \"power_t\": 0,\n",
            "          \"momentum\": 0,\n",
            "          \"use_nesterov_momentum\": false\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: export plain text variable as a text file\n",
        "\n",
        "with open('/content/algoparams_from_ui1.txt', 'w') as file:\n",
        "    file.write(plain_text)\n"
      ],
      "metadata": {
        "id": "eEXdMtJFPuJG"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Read the CSV file\n",
        "file_path = \"/content/iris_modified.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "print(\"CSV file content:\")\n",
        "print(data.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_dIzZrmAQxB",
        "outputId": "cf9e90ca-53a8-46e7-98c9-1e6734a8c2be"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file content:\n",
            "   sepal_length  sepal_width  petal_length  petal_width      species\n",
            "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
            "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
            "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
            "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
            "4           5.0          3.6           1.4          0.2  Iris-setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import json\n",
        "\n",
        "# Load the JSON data from the text file\n",
        "with open(\"/content/algoparams_from_ui1.txt\", \"r\") as file:\n",
        "    json_data = json.load(file)\n",
        "\n",
        "# Extract values from session_info dictionary\n",
        "session_info = json_data['design_state_data']['session_info']\n",
        "session_name = session_info['session_name']\n",
        "session_description = session_info['session_description']\n",
        "project_id = session_info['project_id']\n",
        "experiment_id = session_info['experiment_id']\n",
        "dataset = session_info['dataset']\n",
        "\n",
        "# Display the extracted values\n",
        "print(\"Session Info:\")\n",
        "print(f\"Session Name: {session_name}\")\n",
        "print(f\"Session Description: {session_description}\")\n",
        "print(f\"Project ID: {project_id}\")\n",
        "print(f\"Experiment ID: {experiment_id}\")\n",
        "print(f\"Dataset: {dataset}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiLLdDo7PgeB",
        "outputId": "59280314-cb11-43fb-bbab-c30154d00c9c"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Session Info:\n",
            "Session Name: test\n",
            "Session Description: test\n",
            "Project ID: 1\n",
            "Experiment ID: kkkk-11\n",
            "Dataset: iris_modified.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting information from the 'target' dictionary\n",
        "target_info = json_data['design_state_data']['target']\n",
        "target_variable = target_info['target']\n",
        "prediction_type = target_info['prediction_type']\n",
        "task_type = target_info['type']\n",
        "\n",
        "# Determine if it's a classification or regression task\n",
        "task_type_label = \"Classification\" if task_type.lower() == \"classification\" else \"Regression\"\n",
        "\n",
        "# Display the extracted information\n",
        "print(\"\\nTarget Information:\")\n",
        "print(f\"Target Variable: {target_variable}\")\n",
        "print(f\"Prediction Type: {prediction_type}\")\n",
        "print(f\"Task Type: {task_type_label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJwWPB-KQ6rt",
        "outputId": "b671380e-4e85-4fe5-ef31-9e37a2477f92"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Target Information:\n",
            "Target Variable: species\n",
            "Prediction Type: Classification\n",
            "Task Type: Regression\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the feature_handling dictionary\n",
        "feature_handling = json_data['design_state_data']['feature_handling']\n",
        "\n",
        "# Print the extracted feature_handling dictionary\n",
        "print(feature_handling)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4AShUsTFsV4",
        "outputId": "e4491662-161e-4df4-a178-a02353e36df2"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sepal_length': {'feature_name': 'sepal_length', 'is_selected': True, 'feature_variable_type': 'numerical', 'feature_details': {'numerical_handling': 'Keep as regular numerical feature', 'rescaling': 'No rescaling', 'make_derived_feats': False, 'missing_values': 'Impute', 'impute_with': 'Average of values'}}, 'sepal_width': {'feature_name': 'sepal_width', 'is_selected': True, 'feature_variable_type': 'numerical', 'feature_details': {'numerical_handling': 'Keep as regular numerical feature', 'rescaling': 'No rescaling', 'make_derived_feats': False, 'missing_values': 'Impute', 'impute_with': 'Average of values'}}, 'petal_length': {'feature_name': 'petal_length', 'is_selected': True, 'feature_variable_type': 'numerical', 'feature_details': {'numerical_handling': 'Keep as regular numerical feature', 'rescaling': 'No rescaling', 'make_derived_feats': False, 'missing_values': 'Impute', 'impute_with': 'Average of values'}}, 'petal_width': {'feature_name': 'petal_width', 'is_selected': False, 'feature_variable_type': 'numerical', 'feature_details': {'numerical_handling': 'Keep as regular numerical feature', 'rescaling': 'No rescaling', 'make_derived_feats': False, 'missing_values': 'Impute', 'impute_with': 'Average of values'}}, 'species': {'feature_name': 'species', 'is_selected': True, 'feature_variable_type': 'text', 'feature_details': {'text_handling': 'Tokenize and hash', 'hash_columns': 0}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Iterate over each feature\n",
        "for feature_name, details in feature_handling.items():\n",
        "    if not details.get('is_selected', False):\n",
        "        # Remove the column from the dataframe if not selected\n",
        "        data.drop(columns=[feature_name], inplace=True)\n",
        "        continue\n",
        "\n",
        "    feature_type = details.get('feature_variable_type', None)\n",
        "\n",
        "    if feature_type == 'numerical':\n",
        "        numerical_handling = details['feature_details'].get('numerical_handling', None)\n",
        "        if numerical_handling == 'Keep as regular numerical feature':\n",
        "            # No special handling required for numerical features\n",
        "            pass\n",
        "        elif numerical_handling == 'Rescale':\n",
        "          # Initialize MinMaxScaler\n",
        "            scaler = MinMaxScaler()\n",
        "\n",
        "          # Rescale the column\n",
        "            data[feature_name] = scaler.fit_transform(data[[feature_name]])\n",
        "\n",
        "\n",
        "        elif numerical_handling == 'Impute':\n",
        "            # Impute missing values for numerical features\n",
        "            impute_with = details['feature_details'].get('impute_with', None)\n",
        "            if impute_with == 'Average of values':\n",
        "                data[feature_name].fillna(data[feature_name].mean(), inplace=True)\n",
        "\n",
        "    elif feature_type == 'text':\n",
        "        # Handle text features\n",
        "        text_handling = details['feature_details'].get('text_handling', None)\n",
        "        if text_handling == 'Tokenize and hash':\n",
        "            # Add code for tokenization and hashing if needed\n",
        "            pass\n",
        "\n",
        "# Display the modified data\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fV0iqROoEIZh",
        "outputId": "3907bf97-a08c-43d2-c805-45953cbe5153"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal_length  sepal_width  petal_length      species\n",
            "0           5.1          3.5           1.4  Iris-setosa\n",
            "1           4.9          3.0           1.4  Iris-setosa\n",
            "2           4.7          3.2           1.3  Iris-setosa\n",
            "3           4.6          3.1           1.5  Iris-setosa\n",
            "4           5.0          3.6           1.4  Iris-setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Extract parameters for splitting\n",
        "split_policy = json_data['design_state_data']['train']['policy']\n",
        "time_variable = json_data['design_state_data']['train']['time_variable']\n",
        "sampling_method = json_data['design_state_data']['train']['sampling_method']\n",
        "split_method = json_data['design_state_data']['train']['split']\n",
        "k_fold = json_data['design_state_data']['train']['k_fold']\n",
        "train_ratio = json_data['design_state_data']['train'].get('train_ratio', 0.8)\n",
        "random_seed = json_data['design_state_data']['train'].get('random_seed', None)\n",
        "\n",
        "# Perform dataset splitting based on the specified policy\n",
        "if split_policy == 'Split the dataset':\n",
        "    # Check if the split method is random or time-based\n",
        "    if split_method == 'Randomly':\n",
        "        train_data, test_data = train_test_split(data, train_size=train_ratio, random_state=random_seed)\n",
        "        print(\"Dataset split randomly with train_ratio =\", train_ratio, \"and random_seed =\", random_seed)\n",
        "    elif split_method == 'Time-based':\n",
        "        sorted_data = data.sort_values(by=time_variable)\n",
        "        split_index = int(len(sorted_data) * train_ratio)\n",
        "        train_data = sorted_data[:split_index]\n",
        "        test_data = sorted_data[split_index:]\n",
        "        print(\"Dataset split based on time variable =\", time_variable, \"with train_ratio =\", train_ratio)\n",
        "    else:\n",
        "        print(\"Invalid split method specified in the JSON file.\")\n",
        "else:\n",
        "    print(\"Invalid splitting policy specified in the JSON file.\")\n",
        "\n",
        "# Print the first few rows of train and test data for verification\n",
        "print(\"\\nTrain Data:\")\n",
        "print(train_data.head())\n",
        "print(\"\\nTest Data:\")\n",
        "print(test_data.head())\n",
        "\n",
        "\n",
        "# Assuming 'target' is the target column name (adjust as needed)\n",
        "X_train = train_data.drop(target_variable, axis=1)\n",
        "y_train = train_data[target_variable]\n",
        "\n",
        "X_test = test_data.drop(target_variable, axis=1)\n",
        "y_test = test_data[target_variable]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTl3UzxqYjRi",
        "outputId": "d7fd7e64-00d0-4b68-a4c2-f810006396ea"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset split randomly with train_ratio = 0.8 and random_seed = 10\n",
            "\n",
            "Train Data:\n",
            "     sepal_length  sepal_width  petal_length          species\n",
            "58            6.6          2.9           4.6  Iris-versicolor\n",
            "97            6.2          2.9           4.3  Iris-versicolor\n",
            "129           7.2          3.0           5.8   Iris-virginica\n",
            "114           5.8          2.8           5.1   Iris-virginica\n",
            "146           6.3          2.5           5.0   Iris-virginica\n",
            "\n",
            "Test Data:\n",
            "     sepal_length  sepal_width  petal_length          species\n",
            "87            6.3          2.3           4.4  Iris-versicolor\n",
            "111           6.4          2.7           5.3   Iris-virginica\n",
            "10            5.4          3.7           1.5      Iris-setosa\n",
            "91            6.1          3.0           4.6  Iris-versicolor\n",
            "49            5.0          3.3           1.4      Iris-setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the feature_handling dictionary\n",
        "algorithms = json_data['design_state_data']['algorithms']\n",
        "\n",
        "# Print the extracted feature_handling dictionary\n",
        "print(algorithms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29xRd32wavIL",
        "outputId": "0dcbc677-9ce9-4f3d-88bf-7901f0bbec08"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'RandomForestClassifier': {'model_name': 'Random Forest Classifier', 'is_selected': True, 'min_trees': 10, 'max_trees': 30, 'feature_sampling_statergy': 'Default', 'min_depth': 20, 'max_depth': 30, 'min_samples_per_leaf_min_value': 5, 'min_samples_per_leaf_max_value': 50, 'parallelism': 0}, 'RandomForestRegressor': {'model_name': 'Random Forest Regressor', 'is_selected': False, 'min_trees': 10, 'max_trees': 20, 'feature_sampling_statergy': 'Default', 'min_depth': 20, 'max_depth': 25, 'min_samples_per_leaf_min_value': 5, 'min_samples_per_leaf_max_value': 10, 'parallelism': 0}, 'LinearRegression': {'model_name': 'LinearRegression', 'is_selected': False, 'parallelism': 2, 'min_iter': 30, 'max_iter': 50, 'min_regparam': 0.5, 'max_regparam': 0.8, 'min_elasticnet': 0.5, 'max_elasticnet': 0.8}, 'LogisticRegression': {'model_name': 'LogisticRegression', 'is_selected': False, 'parallelism': 2, 'min_iter': 30, 'max_iter': 50, 'min_regparam': 0.5, 'max_regparam': 0.8, 'min_elasticnet': 0.5, 'max_elasticnet': 0.8}, 'RidgeRegression': {'model_name': 'RidgeRegression', 'is_selected': False, 'regularization_term': 'Specify values to test', 'min_iter': 30, 'max_iter': 50, 'min_regparam': 0.5, 'max_regparam': 0.8}, 'LassoRegression': {'model_name': 'Lasso Regression', 'is_selected': False, 'regularization_term': 'Specify values to test', 'min_iter': 30, 'max_iter': 50, 'min_regparam': 0.5, 'max_regparam': 0.8}, 'ElasticNetRegression': {'model_name': 'Lasso Regression', 'is_selected': False, 'regularization_term': 'Specify values to test', 'min_iter': 30, 'max_iter': 50, 'min_regparam': 0.5, 'max_regparam': 0.8, 'min_elasticnet': 0.5, 'max_elasticnet': 0.8}, 'xg_boost': {'model_name': 'XG Boost', 'is_selected': False, 'use_gradient_boosted_tree': True, 'dart': True, 'tree_method': '', 'random_state': 0, 'max_num_of_trees': 0, 'early_stopping': True, 'early_stopping_rounds': 2, 'max_depth_of_tree': [56, 89], 'learningRate': [89, 76], 'l1_regularization': [77], 'l2_regularization': [78], 'gamma': [68], 'min_child_weight': [67], 'sub_sample': [67], 'col_sample_by_tree': [67], 'replace_missing_values': False, 'parallelism': 0}, 'DecisionTreeRegressor': {'model_name': 'Decision Tree', 'is_selected': False, 'min_depth': 4, 'max_depth': 7, 'use_gini': False, 'use_entropy': True, 'min_samples_per_leaf': [12, 6], 'use_best': True, 'use_random': True}, 'DecisionTreeClassifier': {'model_name': 'Decision Tree', 'is_selected': True, 'min_depth': 4, 'max_depth': 7, 'use_gini': False, 'use_entropy': True, 'min_samples_per_leaf': [12, 6], 'use_best': True, 'use_random': False}, 'SVM': {'model_name': 'Support Vector Machine', 'is_selected': False, 'linear_kernel': True, 'rep_kernel': True, 'polynomial_kernel': True, 'sigmoid_kernel': True, 'c_value': [566, 79], 'auto': True, 'scale': True, 'custom_gamma_values': True, 'tolerance': 7, 'max_iterations': 7}, 'KNN': {'model_name': 'KNN', 'is_selected': False, 'k_value': [78], 'distance_weighting': True, 'neighbour_finding_algorithm': 'Automatic', 'random_state': 0, 'p_value': 0}, 'neural_network': {'model_name': 'Neural Network', 'is_selected': False, 'hidden_layer_sizes': [67, 89], 'activation': '', 'alpha_value': 0, 'max_iterations': 0, 'convergence_tolerance': 0, 'early_stopping': True, 'solver': 'ADAM', 'shuffle_data': True, 'initial_learning_rate': 0, 'automatic_batching': True, 'beta_1': 0, 'beta_2': 0, 'epsilon': 0, 'power_t': 0, 'momentum': 0, 'use_nesterov_momentum': False}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdh = json_data['design_state_data']['algorithms']['RandomForestClassifier']\n",
        "\n",
        "# Print the extracted feature_handling dictionary\n",
        "print(rdh)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trSRKj-K0DeB",
        "outputId": "46465bab-ffda-465f-b76c-9f3e542087da"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'model_name': 'Random Forest Classifier', 'is_selected': True, 'min_trees': 10, 'max_trees': 30, 'feature_sampling_statergy': 'Default', 'min_depth': 20, 'max_depth': 30, 'min_samples_per_leaf_min_value': 5, 'min_samples_per_leaf_max_value': 50, 'parallelism': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def compute_classification_metrics(predictor, X_test, y_test):\n",
        "    # Make predictions\n",
        "      predicted_labels = predictor.predict(X_test)\n",
        "\n",
        "    # Compute confusion matrix\n",
        "      cm = confusion_matrix(y_test, predicted_labels)\n",
        "\n",
        "    # Compute classification report\n",
        "      cr = classification_report(y_test, predicted_labels)\n",
        "\n",
        "      print(cm)\n",
        "      print(cr)"
      ],
      "metadata": {
        "id": "p_jGieU6BJh4"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "def compute_regression_metrics(predictor, X_test, y_test):\n",
        "    # Make predictions\n",
        "    predicted_values = predictor.predict(X_test)\n",
        "\n",
        "    # Compute R-squared\n",
        "    r_squared = r2_score(y_test, predicted_values)\n",
        "\n",
        "    # Compute Adjusted R-squared\n",
        "    n = len(y_test)\n",
        "    p = X_test.shape[1]\n",
        "    adj_r_squared = 1 - (1 - r_squared) * ((n - 1) / (n - p - 1))\n",
        "\n",
        "    # Compute RMSE (Root Mean Squared Error)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, predicted_values))\n",
        "    print(predictor)\n",
        "\n",
        "\n",
        "    print(\"R-squared:\", r_squared)\n",
        "    print(\"Adjusted R-squared:\", adj_r_squared)\n",
        "    print(\"RMSE:\", rmse)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Fy-wxXy4BSpT"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "def build_linear_regression_model(params_dict, X_train, X_test, y_train, y_test):\n",
        "    if params_dict.get('is_selected', False):\n",
        "        # Extract hyperparameters\n",
        "        min_iter = params_dict.get('min_iter', 30)\n",
        "        max_iter = params_dict.get('max_iter', 50)\n",
        "        min_regparam = params_dict.get('min_regparam', 0.5)\n",
        "        max_regparam = params_dict.get('max_regparam', 0.8)\n",
        "        min_elasticnet = params_dict.get('min_elasticnet', 0.5)\n",
        "        max_elasticnet = params_dict.get('max_elasticnet', 0.8)\n",
        "\n",
        "        # Initialize model with hyperparameters\n",
        "        model = LinearRegression(n_jobs=params_dict.get('parallelism', 1))\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        if prediction_type==\"Classification\":\n",
        "          compute_classification_metrics(model,X_test, y_test)\n",
        "        else:\n",
        "          compute_regression_metrics(model, X_test, y_test)\n",
        "        return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8q-6rk1LGAiu"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def build_logistic_regression_model(params_dict, X_train, X_test, y_train, y_test):\n",
        "    if params_dict.get('is_selected', False):\n",
        "        # Extract hyperparameters\n",
        "        min_iter = params_dict.get('min_iter', 30)\n",
        "        max_iter = params_dict.get('max_iter', 50)\n",
        "        min_regparam = params_dict.get('min_regparam', 0.5)\n",
        "        max_regparam = params_dict.get('max_regparam', 0.8)\n",
        "        min_elasticnet = params_dict.get('min_elasticnet', 0.5)\n",
        "        max_elasticnet = params_dict.get('max_elasticnet', 0.8)\n",
        "\n",
        "        # Initialize model with hyperparameters\n",
        "        model = LogisticRegression(n_jobs=params_dict.get('parallelism', 1))\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        if prediction_type==\"Classification\":\n",
        "          compute_classification_metrics(model,X_test, y_test)\n",
        "        else:\n",
        "          compute_regression_metrics(model, X_test, y_test)\n",
        "        return model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-mgJ1ALyG-zq"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "def build_ridge_regression_model(params_dict, X_train, X_test, y_train, y_test):\n",
        "    if params_dict.get('is_selected', False):\n",
        "        # Extract hyperparameters\n",
        "        regularization_term = params_dict.get('regularization_term', 1.0)\n",
        "        min_iter = params_dict.get('min_iter', 30)\n",
        "        max_iter = params_dict.get('max_iter', 50)\n",
        "\n",
        "        # Initialize model with hyperparameters\n",
        "        model = Ridge(alpha=regularization_term,\n",
        "                      max_iter=max_iter,\n",
        "                      min_iter=min_iter)\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        if prediction_type==\"Classification\":\n",
        "          compute_classification_metrics(model,X_test, y_test)\n",
        "        else:\n",
        "          compute_regression_metrics(model, X_test, y_test)\n",
        "        return model\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MqS63j0nH1D2"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "def build_lasso_regression_model(params_dict, X_train, X_test, y_train, y_test, prediction_type):\n",
        "    if params_dict.get('is_selected', False):\n",
        "        # Extract hyperparameters\n",
        "        regularization_term = params_dict.get('regularization_term', 1.0)\n",
        "        min_iter = params_dict.get('min_iter', 30)\n",
        "        max_iter = params_dict.get('max_iter', 50)\n",
        "\n",
        "        # Initialize model with hyperparameters\n",
        "        model = Lasso(alpha=regularization_term,\n",
        "                      max_iter=max_iter,\n",
        "                      min_iter=min_iter)\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        if prediction_type==\"Classification\":\n",
        "          compute_classification_metrics(model,X_test, y_test)\n",
        "        else:\n",
        "          compute_regression_metrics(model, X_test, y_test)\n",
        "        return model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pyugbDU3JEvB"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "def build_elasticnet_regression_model(params_dict, X_train, X_test, y_train, y_test):\n",
        "    if params_dict.get('is_selected', False):\n",
        "        # Extract hyperparameters\n",
        "        regularization_term = params_dict.get('regularization_term', 1.0)\n",
        "        min_iter = params_dict.get('min_iter', 30)\n",
        "        max_iter = params_dict.get('max_iter', 50)\n",
        "        min_regparam = params_dict.get('min_regparam', 0.5)\n",
        "        max_regparam = params_dict.get('max_regparam', 0.8)\n",
        "        min_elasticnet = params_dict.get('min_elasticnet', 0.5)\n",
        "        max_elasticnet = params_dict.get('max_elasticnet', 0.8)\n",
        "\n",
        "        # Initialize model with hyperparameters\n",
        "        model = ElasticNet(alpha=regularization_term,\n",
        "                           l1_ratio=params_dict.get('min_elasticnet', 0.5),\n",
        "                           max_iter=max_iter,\n",
        "                           min_iter=min_iter)\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        if prediction_type==\"Classification\":\n",
        "          compute_classification_metrics(model,X_test, y_test)\n",
        "        else:\n",
        "          compute_regression_metrics(model, X_test, y_test)\n",
        "        return model\n",
        "\n"
      ],
      "metadata": {
        "id": "QApOGFLwJlJV"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "def build_model(params_dict, X_train, X_test, y_train, y_test):\n",
        "    # Extract hyperparameters\n",
        "    min_trees = params_dict.get('min_trees', 10)\n",
        "    max_trees = params_dict.get('max_trees', 30)\n",
        "    min_depth = params_dict.get('min_depth', None)\n",
        "    max_depth = params_dict.get('max_depth', None)\n",
        "    min_samples_per_leaf_min_value = params_dict.get('min_samples_per_leaf_min_value', 5)\n",
        "    parallelism = params_dict.get('parallelism', 0)\n",
        "\n",
        "    # Initialize model with hyperparameters\n",
        "    model = RandomForestClassifier(n_estimators=min_trees,\n",
        "\n",
        "                                   max_depth=max_depth,\n",
        "                                   min_samples_leaf=min_samples_per_leaf_min_value,\n",
        "                                   )\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "    if prediction_type==\"Classification\":\n",
        "      compute_classification_metrics(model,X_test, y_test)\n",
        "    else:\n",
        "      compute_regression_metrics(model, X_test, y_test)\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "39drlz9039NA"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "\n",
        "def regress(params_dict, X_train, y_train):\n",
        "    # Extract hyperparameters\n",
        "    min_trees = params_dict.get('min_trees', 10)\n",
        "    max_trees = params_dict.get('max_trees', 20)\n",
        "    min_depth = params_dict.get('min_depth', None)\n",
        "    max_depth = params_dict.get('max_depth', None)\n",
        "    min_samples_per_leaf_min_value = params_dict.get('min_samples_per_leaf_min_value', 5)\n",
        "    min_samples_per_leaf_max_value = params_dict.get('min_samples_per_leaf_max_value', 10)\n",
        "    parallelism = params_dict.get('parallelism', 0)\n",
        "\n",
        "    # Initialize model with hyperparameters\n",
        "    model = RandomForestRegressor(n_estimators=min_trees,\n",
        "                                   max_depth=max_depth,\n",
        "                                   min_samples_leaf=min_samples_per_leaf_min_value,\n",
        "                                   )\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "    if prediction_type==\"Classification\":\n",
        "      compute_classification_metrics(model,X_test, y_test)\n",
        "    else:\n",
        "      compute_regression_metrics(model, X_test, y_test)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "pJIX-Txi7J8I"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "def build_xgboost_model(params_dict, X_train, X_test, y_train, y_test):\n",
        "    if params_dict.get('is_selected', False):\n",
        "        # Extract hyperparameters\n",
        "        max_depth_of_tree = params_dict.get('max_depth_of_tree', [3, 6])\n",
        "        learning_rate = params_dict.get('learningRate', [0.1, 0.3])\n",
        "        l1_regularization = params_dict.get('l1_regularization', [0])\n",
        "        l2_regularization = params_dict.get('l2_regularization', [0])\n",
        "        gamma = params_dict.get('gamma', [0])\n",
        "        min_child_weight = params_dict.get('min_child_weight', [1])\n",
        "        sub_sample = params_dict.get('sub_sample', [1])\n",
        "        col_sample_by_tree = params_dict.get('col_sample_by_tree', [1])\n",
        "\n",
        "        # Initialize model with hyperparameters\n",
        "        model = xgb.XGBRegressor(max_depth=max_depth_of_tree,\n",
        "                                  learning_rate=learning_rate,\n",
        "                                  reg_alpha=l1_regularization,\n",
        "                                  reg_lambda=l2_regularization,\n",
        "                                  gamma=gamma,\n",
        "                                  min_child_weight=min_child_weight,\n",
        "                                  subsample=sub_sample,\n",
        "                                  colsample_bytree=col_sample_by_tree,\n",
        "                                  objective='reg:squarederror',\n",
        "                                  random_state=params_dict.get('random_state', 0))\n",
        "\n",
        "        # Train the model\n",
        "        eval_set = [(X_train, y_train), (X_test, y_test)]\n",
        "        model.fit(X_train, y_train, eval_metric=\"rmse\", eval_set=eval_set,\n",
        "                  early_stopping_rounds=params_dict.get('early_stopping_rounds', 2))\n",
        "\n",
        "        if prediction_type==\"Classification\":\n",
        "          compute_classification_metrics(model,X_test, y_test)\n",
        "        else:\n",
        "          compute_regression_metrics(model, X_test, y_test)\n",
        "        return model\n",
        "\n"
      ],
      "metadata": {
        "id": "82Q5tyUXJ-9E"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "def build_decision_tree_regressor_model(params_dict, X_train, X_test, y_train, y_test):\n",
        "    if params_dict.get('is_selected', False):\n",
        "        # Extract hyperparameters\n",
        "        min_depth = params_dict.get('min_depth', 4)\n",
        "        max_depth = params_dict.get('max_depth', 7)\n",
        "        min_samples_per_leaf = params_dict.get('min_samples_per_leaf', [12, 6])\n",
        "        criterion = 'entropy' if params_dict.get('use_entropy', True) else 'gini'\n",
        "        splitter = 'best' if params_dict.get('use_best', True) else 'random'\n",
        "\n",
        "        # Initialize model with hyperparameters\n",
        "        model = DecisionTreeRegressor(min_samples_leaf=min_samples_per_leaf,\n",
        "                                       max_depth=max_depth,\n",
        "                                       min_samples_split=min_samples_per_leaf,\n",
        "                                       criterion=criterion,\n",
        "                                       splitter=splitter,\n",
        "                                       random_state=params_dict.get('random_state', None))\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        if prediction_type==\"Classification\":\n",
        "          compute_classification_metrics(model,X_test, y_test)\n",
        "        else:\n",
        "          compute_regression_metrics(model, X_test, y_test)\n",
        "        return model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DxP8isjnKl6K"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "def build_svm_model(params_dict, X_train, X_test, y_train, y_test):\n",
        "    if params_dict.get('is_selected', False):\n",
        "        # Extract hyperparameters\n",
        "        c_values = params_dict.get('c_value', [1.0])\n",
        "        kernels = []\n",
        "        if params_dict.get('linear_kernel', True):\n",
        "            kernels.append('linear')\n",
        "        if params_dict.get('rep_kernel', True):\n",
        "            kernels.append('rbf')\n",
        "        if params_dict.get('polynomial_kernel', True):\n",
        "            kernels.append('poly')\n",
        "        if params_dict.get('sigmoid_kernel', True):\n",
        "            kernels.append('sigmoid')\n",
        "        auto = params_dict.get('auto', True)\n",
        "        scale = params_dict.get('scale', True)\n",
        "        custom_gamma_values = params_dict.get('custom_gamma_values', True)\n",
        "        tolerance = params_dict.get('tolerance', 0.001)\n",
        "        max_iterations = params_dict.get('max_iterations', -1)\n",
        "\n",
        "        # Initialize list to store models\n",
        "        models = []\n",
        "\n",
        "        # Train a model for each combination of C value and kernel\n",
        "        for c in c_values:\n",
        "            for kernel in kernels:\n",
        "                # Initialize model with hyperparameters\n",
        "                model = SVC(C=c, kernel=kernel, probability=True, tol=tolerance, max_iter=max_iterations,\n",
        "                            decision_function_shape='ovr', random_state=params_dict.get('random_state', None))\n",
        "\n",
        "                # Train the model\n",
        "                model.fit(X_train, y_train)\n",
        "\n",
        "                models.append(model)\n",
        "\n",
        "        if prediction_type==\"Classification\":\n",
        "          compute_classification_metrics(model,X_test, y_test)\n",
        "        else:\n",
        "          compute_regression_metrics(model, X_test, y_test)\n",
        "        return model\n"
      ],
      "metadata": {
        "id": "1h0R_HrxNYCN"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "def build_knn_model(params_dict, X_train, X_test, y_train, y_test, prediction_type):\n",
        "    if params_dict.get('is_selected', False):\n",
        "        # Extract hyperparameters\n",
        "        k_values = params_dict.get('k_value', [5])\n",
        "        distance_weighting = params_dict.get('distance_weighting', False)\n",
        "        neighbour_finding_algorithm = params_dict.get('neighbour_finding_algorithm', 'auto')\n",
        "        p_value = params_dict.get('p_value', 2)\n",
        "\n",
        "        # Initialize list to store models\n",
        "        models = []\n",
        "\n",
        "        # Train a model for each value of k\n",
        "        for k in k_values:\n",
        "            # Initialize model with hyperparameters\n",
        "            model = KNeighborsClassifier(n_neighbors=k,\n",
        "                                         weights='distance' if distance_weighting else 'uniform',\n",
        "                                         algorithm=neighbour_finding_algorithm,\n",
        "                                         p=p_value)\n",
        "\n",
        "            # Train the model\n",
        "            model.fit(X_train, y_train)\n",
        "\n",
        "            models.append(model)\n",
        "\n",
        "        if prediction_type==\"Classification\":\n",
        "          compute_classification_metrics(model,X_test, y_test)\n",
        "        else:\n",
        "          compute_regression_metrics(model, X_test, y_test)\n",
        "        return model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tE8rI1RTN4zG"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "def build_neural_network_model(params_dict, X_train, X_test, y_train, y_test, prediction_type):\n",
        "    if params_dict.get('is_selected', False):\n",
        "        # Extract hyperparameters\n",
        "        hidden_layer_sizes = params_dict.get('hidden_layer_sizes', [100])\n",
        "        activation = params_dict.get('activation', 'relu')\n",
        "        alpha_value = params_dict.get('alpha_value', 0.0001)\n",
        "        max_iterations = params_dict.get('max_iterations', 200)\n",
        "        convergence_tolerance = params_dict.get('convergence_tolerance', 1e-4)\n",
        "        early_stopping = params_dict.get('early_stopping', False)\n",
        "        solver = params_dict.get('solver', 'adam')\n",
        "        shuffle_data = params_dict.get('shuffle_data', True)\n",
        "        initial_learning_rate = params_dict.get('initial_learning_rate', 0.001)\n",
        "        automatic_batching = params_dict.get('automatic_batching', False)\n",
        "        beta_1 = params_dict.get('beta_1', 0.9)\n",
        "        beta_2 = params_dict.get('beta_2', 0.999)\n",
        "        epsilon = params_dict.get('epsilon', 1e-8)\n",
        "        power_t = params_dict.get('power_t', 0.5)\n",
        "        momentum = params_dict.get('momentum', 0.9)\n",
        "        use_nesterov_momentum = params_dict.get('use_nesterov_momentum', False)\n",
        "\n",
        "        # Initialize model with hyperparameters\n",
        "        model = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes,\n",
        "                              activation=activation,\n",
        "                              alpha=alpha_value,\n",
        "                              max_iter=max_iterations,\n",
        "                              tol=convergence_tolerance,\n",
        "                              early_stopping=early_stopping,\n",
        "                              solver=solver,\n",
        "                              shuffle=shuffle_data,\n",
        "                              learning_rate_init=initial_learning_rate,\n",
        "                              batch_size='auto' if automatic_batching else 'auto',\n",
        "                              beta_1=beta_1,\n",
        "                              beta_2=beta_2,\n",
        "                              epsilon=epsilon,\n",
        "                              power_t=power_t,\n",
        "                              momentum=momentum,\n",
        "                              nesterovs_momentum=use_nesterov_momentum,\n",
        "                              random_state=params_dict.get('random_state', None))\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        if prediction_type==\"Classification\":\n",
        "          compute_classification_metrics(model,X_test, y_test)\n",
        "        else:\n",
        "          compute_regression_metrics(model, X_test, y_test)\n",
        "        return model\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VPF_Ui2LOo27"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "def build_decision_tree_classifier_model(params_dict, X_train, X_test, y_train, y_test):\n",
        "    if params_dict.get('is_selected', False):\n",
        "        # Extract hyperparameters\n",
        "        min_depth = params_dict.get('min_depth', 4)\n",
        "        max_depth = params_dict.get('max_depth', 7)\n",
        "        min_samples_per_leaf = params_dict.get('min_samples_per_leaf', [12, 6])\n",
        "        criterion = 'entropy' if params_dict.get('use_entropy', True) else 'gini'\n",
        "        splitter = 'best' if params_dict.get('use_best', True) else 'random'\n",
        "\n",
        "        # Initialize model with hyperparameters\n",
        "        model = DecisionTreeClassifier(max_depth=max_depth,\n",
        "                                       min_samples_split=2,\n",
        "                                       criterion=criterion,\n",
        "                                       splitter=splitter,\n",
        "                                       random_state=params_dict.get('random_state', None))\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        if prediction_type==\"Classification\":\n",
        "          compute_classification_metrics(model,X_test, y_test)\n",
        "        else:\n",
        "          compute_regression_metrics(model, X_test, y_test)\n",
        "        return model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "azU_BuMvLwmh"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name, model_params in algorithms.items():\n",
        "  print(model_name, model_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmCvoHNiDy55",
        "outputId": "e70193c6-e31d-4b07-c404-673bac88f825"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier {'model_name': 'Random Forest Classifier', 'is_selected': True, 'min_trees': 10, 'max_trees': 30, 'feature_sampling_statergy': 'Default', 'min_depth': 20, 'max_depth': 30, 'min_samples_per_leaf_min_value': 5, 'min_samples_per_leaf_max_value': 50, 'parallelism': 0}\n",
            "RandomForestRegressor {'model_name': 'Random Forest Regressor', 'is_selected': False, 'min_trees': 10, 'max_trees': 20, 'feature_sampling_statergy': 'Default', 'min_depth': 20, 'max_depth': 25, 'min_samples_per_leaf_min_value': 5, 'min_samples_per_leaf_max_value': 10, 'parallelism': 0}\n",
            "LinearRegression {'model_name': 'LinearRegression', 'is_selected': False, 'parallelism': 2, 'min_iter': 30, 'max_iter': 50, 'min_regparam': 0.5, 'max_regparam': 0.8, 'min_elasticnet': 0.5, 'max_elasticnet': 0.8}\n",
            "LogisticRegression {'model_name': 'LogisticRegression', 'is_selected': False, 'parallelism': 2, 'min_iter': 30, 'max_iter': 50, 'min_regparam': 0.5, 'max_regparam': 0.8, 'min_elasticnet': 0.5, 'max_elasticnet': 0.8}\n",
            "RidgeRegression {'model_name': 'RidgeRegression', 'is_selected': False, 'regularization_term': 'Specify values to test', 'min_iter': 30, 'max_iter': 50, 'min_regparam': 0.5, 'max_regparam': 0.8}\n",
            "LassoRegression {'model_name': 'Lasso Regression', 'is_selected': False, 'regularization_term': 'Specify values to test', 'min_iter': 30, 'max_iter': 50, 'min_regparam': 0.5, 'max_regparam': 0.8}\n",
            "ElasticNetRegression {'model_name': 'Lasso Regression', 'is_selected': False, 'regularization_term': 'Specify values to test', 'min_iter': 30, 'max_iter': 50, 'min_regparam': 0.5, 'max_regparam': 0.8, 'min_elasticnet': 0.5, 'max_elasticnet': 0.8}\n",
            "xg_boost {'model_name': 'XG Boost', 'is_selected': False, 'use_gradient_boosted_tree': True, 'dart': True, 'tree_method': '', 'random_state': 0, 'max_num_of_trees': 0, 'early_stopping': True, 'early_stopping_rounds': 2, 'max_depth_of_tree': [56, 89], 'learningRate': [89, 76], 'l1_regularization': [77], 'l2_regularization': [78], 'gamma': [68], 'min_child_weight': [67], 'sub_sample': [67], 'col_sample_by_tree': [67], 'replace_missing_values': False, 'parallelism': 0}\n",
            "DecisionTreeRegressor {'model_name': 'Decision Tree', 'is_selected': False, 'min_depth': 4, 'max_depth': 7, 'use_gini': False, 'use_entropy': True, 'min_samples_per_leaf': [12, 6], 'use_best': True, 'use_random': True}\n",
            "DecisionTreeClassifier {'model_name': 'Decision Tree', 'is_selected': True, 'min_depth': 4, 'max_depth': 7, 'use_gini': False, 'use_entropy': True, 'min_samples_per_leaf': [12, 6], 'use_best': True, 'use_random': False}\n",
            "SVM {'model_name': 'Support Vector Machine', 'is_selected': False, 'linear_kernel': True, 'rep_kernel': True, 'polynomial_kernel': True, 'sigmoid_kernel': True, 'c_value': [566, 79], 'auto': True, 'scale': True, 'custom_gamma_values': True, 'tolerance': 7, 'max_iterations': 7}\n",
            "KNN {'model_name': 'KNN', 'is_selected': False, 'k_value': [78], 'distance_weighting': True, 'neighbour_finding_algorithm': 'Automatic', 'random_state': 0, 'p_value': 0}\n",
            "neural_network {'model_name': 'Neural Network', 'is_selected': False, 'hidden_layer_sizes': [67, 89], 'activation': '', 'alpha_value': 0, 'max_iterations': 0, 'convergence_tolerance': 0, 'early_stopping': True, 'solver': 'ADAM', 'shuffle_data': True, 'initial_learning_rate': 0, 'automatic_batching': True, 'beta_1': 0, 'beta_2': 0, 'epsilon': 0, 'power_t': 0, 'momentum': 0, 'use_nesterov_momentum': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
        "    # Evaluate on training set\n",
        "    train_predictions = model.predict(X_train)\n",
        "    train_score = model.score(X_train, y_train)  # You can use any appropriate metric here\n",
        "\n",
        "    # Evaluate on testing set\n",
        "    test_predictions = model.predict(X_test)\n",
        "    test_score = model.score(X_test, y_test)  # You can use any appropriate metric here\n",
        "\n",
        "    return train_score, test_score\n",
        "\n",
        "def call_model_functions(algorithms, X_train, X_test, y_train, y_test):\n",
        "    model_build_functions = {\n",
        "        \"RandomForestClassifier\": build_model,\n",
        "        \"RandomForestRegressor\": regress,\n",
        "        \"LinearRegression\": build_linear_regression_model,\n",
        "        \"LogisticRegression\": build_logistic_regression_model,\n",
        "        \"RidgeRegression\": build_ridge_regression_model,\n",
        "        \"LassoRegression\": build_lasso_regression_model,\n",
        "        \"ElasticNetRegression\": build_elasticnet_regression_model,\n",
        "        \"xg_boost\": build_xgboost_model,\n",
        "        \"DecisionTreeRegressor\": build_decision_tree_regressor_model,\n",
        "        \"DecisionTreeClassifier\": build_decision_tree_classifier_model,\n",
        "        \"SVM\": build_svm_model,\n",
        "        \"KNN\": build_knn_model,\n",
        "        \"neural_network\": build_neural_network_model,\n",
        "    }\n",
        "\n",
        "    best_model = None\n",
        "    best_model_name = None\n",
        "    best_test_score = -float('inf')\n",
        "\n",
        "    for model_name, model_params in algorithms.items():\n",
        "        if model_name in model_build_functions:\n",
        "            model_build_function = model_build_functions[model_name]\n",
        "            if model_params.get('is_selected', False):\n",
        "                model = model_build_function(model_params, X_train, X_test, y_train, y_test)\n",
        "                train_score, test_score = evaluate_model(model, X_train, X_test, y_train, y_test)\n",
        "                print(f\"{model_name} Train Score:\", train_score)\n",
        "                print(f\"{model_name} Test Score:\", test_score)\n",
        "                if test_score > best_test_score:\n",
        "                    best_test_score = test_score\n",
        "                    best_model = model\n",
        "                    best_model_name = model_name\n",
        "        else:\n",
        "            print(f\"Sorry, {model_name} is not a valid model name.\")\n",
        "\n",
        "    if best_model:\n",
        "        print(\"Model Evaluation Report\")\n",
        "        print(\"-----------------------\")\n",
        "        print(f\"Best Model: {best_model_name}\")\n",
        "        return best_model\n",
        "    else:\n",
        "        print(\"No models were selected.\")\n",
        "\n",
        "# Example usage:\n",
        "best_model = call_model_functions(algorithms, X_train, X_test, y_train, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wn6yLuytfYd1",
        "outputId": "cf7442d6-5fa1-4444-ae25-bcf567d82463"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[10  0  0]\n",
            " [ 0 11  2]\n",
            " [ 0  0  7]]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "    Iris-setosa       1.00      1.00      1.00        10\n",
            "Iris-versicolor       1.00      0.85      0.92        13\n",
            " Iris-virginica       0.78      1.00      0.88         7\n",
            "\n",
            "       accuracy                           0.93        30\n",
            "      macro avg       0.93      0.95      0.93        30\n",
            "   weighted avg       0.95      0.93      0.93        30\n",
            "\n",
            "RandomForestClassifier Train Score: 0.9583333333333334\n",
            "RandomForestClassifier Test Score: 0.9333333333333333\n",
            "[[10  0  0]\n",
            " [ 0 12  1]\n",
            " [ 0  0  7]]\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "    Iris-setosa       1.00      1.00      1.00        10\n",
            "Iris-versicolor       1.00      0.92      0.96        13\n",
            " Iris-virginica       0.88      1.00      0.93         7\n",
            "\n",
            "       accuracy                           0.97        30\n",
            "      macro avg       0.96      0.97      0.96        30\n",
            "   weighted avg       0.97      0.97      0.97        30\n",
            "\n",
            "DecisionTreeClassifier Train Score: 0.9916666666666667\n",
            "DecisionTreeClassifier Test Score: 0.9666666666666667\n",
            "Model Evaluation Report\n",
            "-----------------------\n",
            "Best Model: DecisionTreeClassifier\n"
          ]
        }
      ]
    }
  ]
}